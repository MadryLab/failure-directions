{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "aeda6f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "import src.svm_utils as svm_utils\n",
    "import src.visualization_utils as viz_utils\n",
    "import src.ds_utils as ds_utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import src.pytorch_datasets as pytorch_datasets\n",
    "import tqdm\n",
    "\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c8101dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22433/22433 [00:35<00:00, 640.27it/s]\n"
     ]
    }
   ],
   "source": [
    "DS_ROOT = \"/mnt/nfs/datasets/ChestX-ray14\"\n",
    "test_ds = pytorch_datasets.ChestXrayDataSet('test', DS_ROOT)\n",
    "annot_name = os.path.join(DS_ROOT, \"chestxray_metadata_2017_v2020.csv\")\n",
    "annotations = pd.read_csv(annot_name)\n",
    "test_image_names = [os.path.basename(u) for u in  test_ds.image_names]\n",
    "\n",
    "big_index = annotations['Image Index'].to_numpy()\n",
    "test_subset = []\n",
    "for u in tqdm.tqdm(test_image_names):\n",
    "    test_subset.append(np.where(big_index == u)[0][0])\n",
    "test_annotations = annotations.loc[test_subset].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba4414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "dbb4598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "beton_root = \"/mnt/cfs/projects/correlated_errors/betons\"\n",
    "experiment_root = \"/mnt/cfs/projects/correlated_errors/experiments/chestxray/\"\n",
    "condition = 2\n",
    "\n",
    "primary_condition ={\n",
    "    2: 'Effusion',\n",
    "    3: 'Infiltration',\n",
    "    4: 'Mass',\n",
    "}[condition]\n",
    "\n",
    "name = os.path.join(experiment_root, f\"svm_checkpoints/chestxray_svm_{condition}.pt\") # SVM output file\n",
    "model_root = os.path.join(experiment_root, \"models\")\n",
    "model_ckpt = os.path.join(model_root, \"vanilla_chestxray/version_3/checkpoints/checkpoint_last.pt\")\n",
    "loss_upweight_root = os.path.join(experiment_root, \"loss_vec_files\")\n",
    "subset_root = os.path.join(experiment_root, \"subset_index_files\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf233a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------val_metrics--------------\n",
      "{'Confusion Matrix': array([[1179,  217],\n",
      "       [2049, 7774]]),\n",
      " 'Model Accuracy': 0.8755682324627864,\n",
      " 'SVM Accuracy': 0.7980211973190308,\n",
      " 'SVM Balanced Accuracy': 0.8179818987846375}\n",
      "-----------train_metrics--------------\n",
      "{'Confusion Matrix': array([[ 5463,  1971],\n",
      "       [17036, 53998]]),\n",
      " 'Model Accuracy': 0.9052607432329103,\n",
      " 'SVM Accuracy': 0.7577738761901855,\n",
      " 'SVM Balanced Accuracy': 0.7475190162658691}\n",
      "-----------test_metrics--------------\n",
      "{'Confusion Matrix': array([[ 1967,   864],\n",
      "       [ 4338, 15264]]),\n",
      " 'Model Accuracy': 0.8738019881424687,\n",
      " 'SVM Accuracy': 0.7681095004081726,\n",
      " 'SVM Balanced Accuracy': 0.7367517650127411}\n",
      "Using default os_cache: False\n",
      "Using default quasi_random: False\n",
      "Using default val_aug: None\n",
      "Using default indices_file: None\n",
      "Using default unlabeled_beton: None\n",
      "Using default loss_upweight: 5\n",
      "\n",
      "-----------CONFIG--------------\n",
      "{   'arch': 'resnet18',\n",
      "    'arch_type': 'resnet',\n",
      "    'batch_size': 100,\n",
      "    'bce': True,\n",
      "    'drop_last': False,\n",
      "    'imgsz': 224,\n",
      "    'indices_file': None,\n",
      "    'loss_upweight': 5,\n",
      "    'mean': [123.675, 116.28, 103.53],\n",
      "    'num_classes': 14,\n",
      "    'num_workers': 10,\n",
      "    'os_cache': False,\n",
      "    'quasi_random': True,\n",
      "    'shuffle': False,\n",
      "    'std': [58.395, 57.12, 57.375],\n",
      "    'test_beton': 'chestxray/chestxray_test.beton',\n",
      "    'train_aug': 'imagenet_train_aug',\n",
      "    'train_beton': 'chestxray/chestxray_train.beton',\n",
      "    'train_img_decoder': 'center_crop_256',\n",
      "    'training': {   'epochs': 16,\n",
      "                    'lr': 0.5,\n",
      "                    'lr_scheduler': {'lr_peak_epoch': 2, 'type': 'cyclic'},\n",
      "                    'optimizer': {'momentum': 0.9, 'weight_decay': 0.0005}},\n",
      "    'unlabeled_beton': None,\n",
      "    'val_aug': None,\n",
      "    'val_beton': 'chestxray/chestxray_val.beton',\n",
      "    'val_img_decoder': 'center_crop_256'}\n",
      "{'training_args': {'epochs': 16, 'lr': 0.5, 'optimizer': {'momentum': 0.9, 'weight_decay': 0.0005}, 'lr_scheduler': {'type': 'cyclic', 'lr_peak_epoch': 2}, 'iters_per_epoch': 76}, 'epoch': 15, 'training_metrics': {'loss': 0.14136522969132975, 'acc': 0.951453688113313}, 'val_metrics': {'loss': 0.15498142369700493, 'acc': 0.9493525356402296}}\n",
      "getting train loader\n",
      "getting val loader\n",
      "getting test loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [00:12<00:00, 63.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9054136872291565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:02<00:00, 40.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8755682110786438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 64/225 [00:02<00:02, 62.53it/s]"
     ]
    }
   ],
   "source": [
    "processor = viz_utils.SVMProcessor(name, root=beton_root, checkpoint_path=model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa66e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secondary_conditions(findings_list):\n",
    "    secondary_conditions = []\n",
    "    for u in test_findings:\n",
    "        secondary_condition = False\n",
    "        for u2 in u:\n",
    "            if u2 == \"No Finding\" or u2 == primary_condition:\n",
    "                continue\n",
    "            else:\n",
    "                secondary_condition = True\n",
    "        secondary_conditions.append(secondary_condition)\n",
    "    secondary_conditions = np.array(secondary_conditions)\n",
    "    return secondary_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b930a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display extremes for original model\n",
    "for c in range(2):\n",
    "    processor.display_extremes(c, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4184f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'test'\n",
    "test_dv = processor.metrics[f'{split}_metrics']['decision_values']\n",
    "test_confs = processor.run_dict[split]['confs']\n",
    "test_class = processor.metrics[f'{split}_metrics']['classes'] # 0 if female, 1 if male\n",
    "test_pred_correct = processor.metrics[f'{split}_metrics']['ypred']\n",
    "test_correct = processor.metrics[f'{split}_metrics']['ytrue']\n",
    "test_findings = [u.split('|') for u in tqdm.tqdm(test_annotations['Finding Labels'].to_numpy())]\n",
    "test_healthy = test_annotations['Finding Labels'] == 'No Finding'\n",
    "test_secondary_conditions = get_secondary_conditions(test_findings)\n",
    "test_male = (test_annotations['Patient Gender'] == 'M').to_numpy()\n",
    "test_PA = (test_annotations['View Position'] == 'PA').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23a7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_annotations[test_class==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245080a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sklearn_metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "def print_confusion_matrices(test_problematic, condition_name, class_mask=None):\n",
    "    if class_mask is None:\n",
    "        class_mask = np.ones(len(test_problematic)).astype(bool)\n",
    "        \n",
    "    problematic = test_problematic[class_mask]\n",
    "    correct = test_correct[class_mask]\n",
    "    pred_correct = test_pred_correct[class_mask]\n",
    "    dv_order = np.argsort(test_dv[class_mask])\n",
    "    conf_order = np.argsort(test_confs[class_mask])\n",
    "    \n",
    "    print(f\"Percentage that is {condition_name}: {problematic.mean():0.2%}\")\n",
    "    print(f\"Percentage that is incorrect: {(correct==0).mean():0.2%}\")\n",
    "    print(f\"Percentage that is flagged: {(pred_correct==0).mean():0.2%}\")\n",
    "    print(\"--\")\n",
    "    \n",
    "    fig, ax_ = plt.subplots(1, 3, figsize=(18, 4))\n",
    "\n",
    "    ax = ax_[0]\n",
    "    conf_matrix = sklearn_metrics.confusion_matrix(y_true=(problematic == 0), y_pred=correct)\n",
    "    sns.heatmap(conf_matrix/conf_matrix.sum(), fmt='.2%', annot=True, cmap='Blues', ax=ax)\n",
    "    ax.yaxis.set_ticklabels([f'{condition_name}', f'Not {condition_name}'])\n",
    "    ax.xaxis.set_ticklabels(['Incorrect', 'Correct'])\n",
    "    perc_incorr_that_is_prob = (problematic & (correct == 0)).sum()/(correct == 0).sum()\n",
    "    perc_prob_that_is_incorr = (problematic & (correct == 0)).sum()/(problematic).sum()\n",
    "    print(f\"percentage incorrect that is {condition_name} {perc_incorr_that_is_prob:0.3%}\")\n",
    "    print(f\"percentage {condition_name} that is incorrect {perc_prob_that_is_incorr:0.3%}\")\n",
    "\n",
    "    print(\"-\")\n",
    "    conf_matrix = sklearn_metrics.confusion_matrix(y_true=(problematic == 0), y_pred=pred_correct)\n",
    "    ax = ax_[1]\n",
    "    sns.heatmap(conf_matrix/conf_matrix.sum(), fmt='.2%', annot=True, cmap='Blues', ax=ax)\n",
    "    ax.yaxis.set_ticklabels([f'{condition_name}', f'Not {condition_name}'])\n",
    "    ax.xaxis.set_ticklabels(['Predicted Incorrect', 'Predicted Correct'])\n",
    "    perc_incorr_that_is_prob = (problematic & (pred_correct == 0)).sum()/(pred_correct == 0).sum()\n",
    "    perc_prob_that_is_incorr = (problematic & (pred_correct == 0)).sum()/(problematic).sum()\n",
    "    print(f\"percentage flagged that is {condition_name} {perc_incorr_that_is_prob:0.3%}\")\n",
    "    print(f\"percentage {condition_name} that is flagged {perc_prob_that_is_incorr:0.3%}\")\n",
    "    \n",
    "    K_range = np.arange(10, len(problematic), 10) \n",
    "    df = []\n",
    "    def compute_fraction(arr):\n",
    "        return arr.sum()/len(arr)\n",
    "    \n",
    "    for K in K_range:\n",
    "        df.append([\n",
    "            K,\n",
    "            compute_fraction(problematic[dv_order[:K]]),\n",
    "            compute_fraction(problematic[conf_order[:K]]),\n",
    "            compute_fraction(problematic),\n",
    "        ])\n",
    "    df = pd.DataFrame(df, columns=['Top K', 'SVM', 'Confidence', 'All'])\n",
    "    df = df.melt(['Top K'], var_name='Method', value_name=f'Fraction {condition_name}')\n",
    "    sns.lineplot(data=df, x='Top K', y=f'Fraction {condition_name}', hue='Method', ax=ax_[2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5dc227",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for class_mask, name in [\n",
    "    (None, f\"All\"),\n",
    "    (test_class==0, f\"No {primary_condition}\"), \n",
    "    (test_class==1, f\"{primary_condition}\")]:\n",
    "    print(\"------------------------\", name, \"------------------------\")\n",
    "    print_confusion_matrices(~test_PA, \"AP\", class_mask=class_mask)\n",
    "#     print_confusion_matrices(test_secondary_conditions, \"sec. cond.\", class_mask=class_mask)\n",
    "#     print_confusion_matrices(~test_male, \"female\", class_mask=class_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e1796d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
