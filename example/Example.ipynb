{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "819cbdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/home/saachij/conda_envs/ffcv_cfs/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import failure_directions\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.cuda.amp import autocast\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50d1b2",
   "metadata": {},
   "source": [
    "# Training the base model\n",
    "\n",
    "First, we're going to train a CIFAR-10 model. We just put an example setup here (make sure to evaluate these cells, but feel free to skip to the next section for our method!)\n",
    "\n",
    "### Setting up the dataset\n",
    "Ok, first let's set up the dataset. We're going to use CIFAR-10, so let's download it below.\n",
    "\n",
    "We are going to train on 20% of the training dataset, and will let another 20% be validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee9b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'mean': [125.307, 122.961, 113.8575], 'std': [51.5865, 50.847, 51.255],\n",
    "    'num_classes': 10, 'arch': 'resnet18', 'arch_type': 'cifar_resnet', 'batch_size': 512,\n",
    "    'training': {\n",
    "        'epochs': 35, 'lr': 0.5,\n",
    "        'optimizer': {'momentum': 0.9, 'weight_decay': 5.0E-4},\n",
    "        'lr_scheduler':{'type': 'cyclic', 'lr_peak_epoch': 5}\n",
    "    }\n",
    "}\n",
    "\n",
    "fill_color = tuple(map(int, hparams['mean']))\n",
    "\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=np.array(hparams['mean'])/255, std=np.array(hparams['std'])/255)])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    base_transform\n",
    "])\n",
    "\n",
    "# For visualization\n",
    "INV_NORM = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [255/x for x in hparams['std']]),\n",
    "                                transforms.Normalize(mean = [-x /255 for x in hparams['mean']],\n",
    "                                                     std = [ 1., 1., 1. ])])\n",
    "TOIMAGE = transforms.Compose([INV_NORM, transforms.ToPILImage()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e757b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_root = \"/mnt/cfs/datasets/cifar\"\n",
    "orig_train_ds = torchvision.datasets.CIFAR10(ds_root, train=True, transform=base_transform)\n",
    "aug_train_ds = torchvision.datasets.CIFAR10(ds_root, train=True, transform=train_transform)\n",
    "test_ds = torchvision.datasets.CIFAR10(ds_root, train=False, transform=base_transform)\n",
    "\n",
    "all_train_indices = torch.arange(len(orig_train_ds))\n",
    "val_indices = all_train_indices[::5]\n",
    "train_indices = all_train_indices[1::5]\n",
    "\n",
    "train_ds = torch.utils.data.Subset(aug_train_ds, train_indices)\n",
    "val_ds = torch.utils.data.Subset(orig_train_ds, val_indices)\n",
    "no_aug_train_ds = torch.utils.data.Subset(orig_train_ds, train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ff8924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = hparams['batch_size']\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=bsz, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=bsz, shuffle=False, drop_last=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=bsz, shuffle=False, drop_last=False)\n",
    "no_aug_train_loader = torch.utils.data.DataLoader(no_aug_train_ds, batch_size=bsz, shuffle=False, drop_last=False)\n",
    "\n",
    "loaders = {'train': no_aug_train_loader, 'test': test_loader, 'val': val_loader} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3703d82b",
   "metadata": {},
   "source": [
    "### Training a Model\n",
    "Ok, let's train a model. We'll train a ResNet-18. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9621ea2d",
   "metadata": {},
   "source": [
    "we have a pre-trained model [here](https://www.dropbox.com/s/1gtlmbe4k2dzh9w/example_ckpt.pt?dl=0) if you don't want to wait for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d47a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_args': {'epochs': 35, 'lr': 0.5, 'optimizer': {'momentum': 0.9, 'weight_decay': 0.0005}, 'lr_scheduler': {'type': 'cyclic', 'lr_peak_epoch': 5}, 'iters_per_epoch': 19}, 'epoch': 34, 'training_metrics': {'loss': 0.29991454199740764, 'acc': 0.8988486842105263}, 'val_metrics': {'loss': 0.7290558261871338, 'acc': 0.7687000005722046}}\n"
     ]
    }
   ],
   "source": [
    "# if you've already trained the model just load it here\n",
    "build_fn = failure_directions.model_utils.BUILD_FUNCTIONS[hparams['arch_type']]\n",
    "path = \"example_ckpt.pt\"\n",
    "model = failure_directions.model_utils.load_model(path, build_fn)\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f40151",
   "metadata": {},
   "source": [
    "otherwise, train it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17b6ee52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging in  runs/temp/version_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0: 100%|██████████| 19/19 [00:05<00:00,  3.48it/s, loss=2.94, acc=0.184]\n",
      "Val Epoch: 0: 100%|██████████| 20/20 [00:03<00:00,  5.71it/s, loss=1.33e+3, acc=0.0846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.09999999999999999, Train Loss: 2.6122, Train Acc: 0.1816, Val Loss: 1494.3194, Val Acc: 0.0977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1: 100%|██████████| 19/19 [00:05<00:00,  3.53it/s, loss=2.39, acc=0.201]\n",
      "Val Epoch: 1: 100%|██████████| 20/20 [00:03<00:00,  5.77it/s, loss=308, acc=0.11]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.19999999999999998, Train Loss: 2.4504, Train Acc: 0.1882, Val Loss: 324.7413, Val Acc: 0.1040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2: 100%|██████████| 19/19 [00:06<00:00,  3.15it/s, loss=1.98, acc=0.279]\n",
      "Val Epoch: 2: 100%|██████████| 20/20 [00:03<00:00,  5.62it/s, loss=15.1, acc=0.162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3, Train Loss: 2.1094, Train Acc: 0.2320, Val Loss: 16.2994, Val Acc: 0.1311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3: 100%|██████████| 19/19 [00:05<00:00,  3.45it/s, loss=1.81, acc=0.332]\n",
      "Val Epoch: 3: 100%|██████████| 20/20 [00:03<00:00,  5.84it/s, loss=1.95, acc=0.283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.39999999999999997, Train Loss: 1.8803, Train Acc: 0.2916, Val Loss: 1.9887, Val Acc: 0.2634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4: 100%|██████████| 19/19 [00:05<00:00,  3.48it/s, loss=1.86, acc=0.312]\n",
      "Val Epoch: 4: 100%|██████████| 20/20 [00:03<00:00,  5.78it/s, loss=1.67, acc=0.349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.5, Train Loss: 1.7976, Train Acc: 0.3221, Val Loss: 1.7531, Val Acc: 0.3246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5: 100%|██████████| 19/19 [00:05<00:00,  3.48it/s, loss=1.69, acc=0.354]\n",
      "Val Epoch: 5: 100%|██████████| 20/20 [00:03<00:00,  5.88it/s, loss=1.54, acc=0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.48333333333333334, Train Loss: 1.6979, Train Acc: 0.3561, Val Loss: 1.6381, Val Acc: 0.3828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6: 100%|██████████| 19/19 [00:05<00:00,  3.49it/s, loss=1.54, acc=0.414]\n",
      "Val Epoch: 6: 100%|██████████| 20/20 [00:03<00:00,  5.96it/s, loss=1.51, acc=0.419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4666666666666667, Train Loss: 1.6531, Train Acc: 0.3815, Val Loss: 1.6290, Val Acc: 0.3787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7: 100%|██████████| 19/19 [00:05<00:00,  3.52it/s, loss=1.61, acc=0.391]\n",
      "Val Epoch: 7: 100%|██████████| 20/20 [00:03<00:00,  5.88it/s, loss=1.65, acc=0.397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.45, Train Loss: 1.5735, Train Acc: 0.4160, Val Loss: 1.7838, Val Acc: 0.3517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8: 100%|██████████| 19/19 [00:05<00:00,  3.44it/s, loss=1.49, acc=0.434]\n",
      "Val Epoch: 8: 100%|██████████| 20/20 [00:03<00:00,  5.99it/s, loss=1.49, acc=0.452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.43333333333333335, Train Loss: 1.4960, Train Acc: 0.4440, Val Loss: 1.5395, Val Acc: 0.4179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9: 100%|██████████| 19/19 [00:05<00:00,  3.49it/s, loss=1.38, acc=0.484]\n",
      "Val Epoch: 9: 100%|██████████| 20/20 [00:03<00:00,  5.94it/s, loss=1.6, acc=0.43]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4166666666666667, Train Loss: 1.4351, Train Acc: 0.4676, Val Loss: 1.6748, Val Acc: 0.3919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10: 100%|██████████| 19/19 [00:05<00:00,  3.49it/s, loss=1.37, acc=0.512]\n",
      "Val Epoch: 10: 100%|██████████| 20/20 [00:03<00:00,  5.82it/s, loss=1.59, acc=0.445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4, Train Loss: 1.3705, Train Acc: 0.5002, Val Loss: 1.6846, Val Acc: 0.4032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11: 100%|██████████| 19/19 [00:05<00:00,  3.45it/s, loss=1.37, acc=0.508]\n",
      "Val Epoch: 11: 100%|██████████| 20/20 [00:03<00:00,  5.67it/s, loss=1.44, acc=0.478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3833333333333333, Train Loss: 1.3379, Train Acc: 0.5155, Val Loss: 1.4714, Val Acc: 0.4682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12: 100%|██████████| 19/19 [00:05<00:00,  3.51it/s, loss=1.22, acc=0.541]\n",
      "Val Epoch: 12: 100%|██████████| 20/20 [00:03<00:00,  5.86it/s, loss=1.21, acc=0.559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3666666666666667, Train Loss: 1.2821, Train Acc: 0.5343, Val Loss: 1.2660, Val Acc: 0.5286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13: 100%|██████████| 19/19 [00:05<00:00,  3.50it/s, loss=1.18, acc=0.566]\n",
      "Val Epoch: 13: 100%|██████████| 20/20 [00:03<00:00,  5.88it/s, loss=1.43, acc=0.515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.35, Train Loss: 1.1885, Train Acc: 0.5692, Val Loss: 1.4955, Val Acc: 0.4711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14: 100%|██████████| 19/19 [00:05<00:00,  3.49it/s, loss=1.16, acc=0.594]\n",
      "Val Epoch: 14: 100%|██████████| 20/20 [00:03<00:00,  5.85it/s, loss=1.33, acc=0.533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.33333333333333337, Train Loss: 1.1768, Train Acc: 0.5758, Val Loss: 1.3544, Val Acc: 0.5056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15: 100%|██████████| 19/19 [00:05<00:00,  3.50it/s, loss=1.08, acc=0.639]\n",
      "Val Epoch: 15: 100%|██████████| 20/20 [00:03<00:00,  5.99it/s, loss=1.22, acc=0.562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.31666666666666665, Train Loss: 1.1150, Train Acc: 0.5965, Val Loss: 1.2963, Val Acc: 0.5419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16: 100%|██████████| 19/19 [00:05<00:00,  3.41it/s, loss=1.01, acc=0.625] \n",
      "Val Epoch: 16: 100%|██████████| 20/20 [00:03<00:00,  5.44it/s, loss=1.06, acc=0.673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3, Train Loss: 1.0644, Train Acc: 0.6183, Val Loss: 1.1561, Val Acc: 0.5895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17: 100%|██████████| 19/19 [00:05<00:00,  3.46it/s, loss=0.962, acc=0.625]\n",
      "Val Epoch: 17: 100%|██████████| 20/20 [00:03<00:00,  5.93it/s, loss=1.25, acc=0.57] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.2833333333333333, Train Loss: 0.9903, Train Acc: 0.6447, Val Loss: 1.3323, Val Acc: 0.5403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18: 100%|██████████| 19/19 [00:05<00:00,  3.48it/s, loss=0.964, acc=0.645]\n",
      "Val Epoch: 18: 100%|██████████| 20/20 [00:03<00:00,  5.88it/s, loss=1.12, acc=0.596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.26666666666666666, Train Loss: 0.9445, Train Acc: 0.6642, Val Loss: 1.1601, Val Acc: 0.6028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19: 100%|██████████| 19/19 [00:05<00:00,  3.46it/s, loss=0.982, acc=0.631]\n",
      "Val Epoch: 19: 100%|██████████| 20/20 [00:03<00:00,  5.99it/s, loss=1.15, acc=0.621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.25, Train Loss: 0.8863, Train Acc: 0.6875, Val Loss: 1.2314, Val Acc: 0.5949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20: 100%|██████████| 19/19 [00:05<00:00,  3.49it/s, loss=0.904, acc=0.688]\n",
      "Val Epoch: 20: 100%|██████████| 20/20 [00:03<00:00,  5.93it/s, loss=0.988, acc=0.636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.23333333333333334, Train Loss: 0.8905, Train Acc: 0.6869, Val Loss: 1.0902, Val Acc: 0.6277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21: 100%|██████████| 19/19 [00:05<00:00,  3.48it/s, loss=0.819, acc=0.705]\n",
      "Val Epoch: 21: 100%|██████████| 20/20 [00:03<00:00,  6.02it/s, loss=1.06, acc=0.651] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.21666666666666667, Train Loss: 0.8213, Train Acc: 0.7031, Val Loss: 1.0552, Val Acc: 0.6296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22: 100%|██████████| 19/19 [00:05<00:00,  3.54it/s, loss=0.808, acc=0.717]\n",
      "Val Epoch: 22: 100%|██████████| 20/20 [00:03<00:00,  5.84it/s, loss=0.891, acc=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.2, Train Loss: 0.7617, Train Acc: 0.7319, Val Loss: 0.9939, Val Acc: 0.6586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23: 100%|██████████| 19/19 [00:05<00:00,  3.52it/s, loss=0.708, acc=0.734]\n",
      "Val Epoch: 23: 100%|██████████| 20/20 [00:03<00:00,  6.05it/s, loss=1.05, acc=0.68] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.18333333333333335, Train Loss: 0.7223, Train Acc: 0.7439, Val Loss: 1.0754, Val Acc: 0.6280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24: 100%|██████████| 19/19 [00:05<00:00,  3.38it/s, loss=0.703, acc=0.74] \n",
      "Val Epoch: 24: 100%|██████████| 20/20 [00:03<00:00,  5.89it/s, loss=0.902, acc=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.16666666666666669, Train Loss: 0.6727, Train Acc: 0.7581, Val Loss: 0.9621, Val Acc: 0.6780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25: 100%|██████████| 19/19 [00:05<00:00,  3.46it/s, loss=0.693, acc=0.75] \n",
      "Val Epoch: 25: 100%|██████████| 20/20 [00:03<00:00,  5.90it/s, loss=1.06, acc=0.658] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.14999999999999997, Train Loss: 0.6539, Train Acc: 0.7710, Val Loss: 1.0998, Val Acc: 0.6483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26: 100%|██████████| 19/19 [00:05<00:00,  3.50it/s, loss=0.652, acc=0.771]\n",
      "Val Epoch: 26: 100%|██████████| 20/20 [00:03<00:00,  5.82it/s, loss=0.988, acc=0.651]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.1333333333333333, Train Loss: 0.6084, Train Acc: 0.7857, Val Loss: 0.9424, Val Acc: 0.6783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27: 100%|██████████| 19/19 [00:05<00:00,  3.44it/s, loss=0.532, acc=0.803]\n",
      "Val Epoch: 27: 100%|██████████| 20/20 [00:03<00:00,  5.80it/s, loss=0.71, acc=0.757] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.11666666666666664, Train Loss: 0.5729, Train Acc: 0.7978, Val Loss: 0.8601, Val Acc: 0.7207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28: 100%|██████████| 19/19 [00:05<00:00,  3.49it/s, loss=0.511, acc=0.824]\n",
      "Val Epoch: 28: 100%|██████████| 20/20 [00:03<00:00,  5.86it/s, loss=0.795, acc=0.746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.09999999999999998, Train Loss: 0.5297, Train Acc: 0.8120, Val Loss: 0.8882, Val Acc: 0.7149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29: 100%|██████████| 19/19 [00:05<00:00,  3.51it/s, loss=0.476, acc=0.832]\n",
      "Val Epoch: 29: 100%|██████████| 20/20 [00:03<00:00,  5.91it/s, loss=0.91, acc=0.732] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.08333333333333331, Train Loss: 0.4910, Train Acc: 0.8236, Val Loss: 0.8804, Val Acc: 0.7073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30: 100%|██████████| 19/19 [00:05<00:00,  3.52it/s, loss=0.447, acc=0.844]\n",
      "Val Epoch: 30: 100%|██████████| 20/20 [00:03<00:00,  5.95it/s, loss=0.811, acc=0.75] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.06666666666666665, Train Loss: 0.4594, Train Acc: 0.8359, Val Loss: 0.8439, Val Acc: 0.7208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31: 100%|██████████| 19/19 [00:05<00:00,  3.52it/s, loss=0.422, acc=0.85] \n",
      "Val Epoch: 31: 100%|██████████| 20/20 [00:03<00:00,  5.89it/s, loss=0.792, acc=0.776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.04999999999999999, Train Loss: 0.4147, Train Acc: 0.8533, Val Loss: 0.7955, Val Acc: 0.7397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32: 100%|██████████| 19/19 [00:05<00:00,  3.50it/s, loss=0.38, acc=0.869] \n",
      "Val Epoch: 32: 100%|██████████| 20/20 [00:03<00:00,  5.93it/s, loss=0.732, acc=0.776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.033333333333333326, Train Loss: 0.3746, Train Acc: 0.8699, Val Loss: 0.7592, Val Acc: 0.7544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33: 100%|██████████| 19/19 [00:05<00:00,  3.51it/s, loss=0.359, acc=0.865]\n",
      "Val Epoch: 33: 100%|██████████| 20/20 [00:03<00:00,  5.95it/s, loss=0.727, acc=0.757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.016666666666666663, Train Loss: 0.3329, Train Acc: 0.8844, Val Loss: 0.7372, Val Acc: 0.7672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 34: 100%|██████████| 19/19 [00:05<00:00,  3.49it/s, loss=0.298, acc=0.898]\n",
      "Val Epoch: 34: 100%|██████████| 20/20 [00:03<00:00,  5.91it/s, loss=0.736, acc=0.772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.0, Train Loss: 0.2999, Train Acc: 0.8988, Val Loss: 0.7291, Val Acc: 0.7687\n"
     ]
    }
   ],
   "source": [
    "build_fn = failure_directions.model_utils.BUILD_FUNCTIONS[hparams['arch_type']]\n",
    "model = build_fn(hparams['arch'], hparams['num_classes'])\n",
    "model = model.cuda()\n",
    "\n",
    "training_args=hparams['training']\n",
    "training_args['iters_per_epoch'] = len(train_loader)\n",
    "trainer = failure_directions.LightWeightTrainer(training_args=hparams['training'],\n",
    "                                                exp_name='temp', enable_logging=True,\n",
    "                                                bce=False, set_device=True)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8cf12b",
   "metadata": {},
   "source": [
    "now let's evaluate the model and get the predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f80e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(loader):\n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            gts, preds, confs = [], [], []\n",
    "            for x, y in tqdm(loader):\n",
    "                x = x.cuda()\n",
    "                logits = model(x)\n",
    "                gts.append(y.cpu())\n",
    "                preds.append(logits.argmax(-1).cpu())\n",
    "                softmax_logits = nn.Softmax(dim=-1)(logits)\n",
    "                confs.append(softmax_logits[torch.arange(logits.shape[0]), y].cpu())\n",
    "    gts = torch.cat(gts).numpy()\n",
    "    preds = torch.cat(preds).numpy()\n",
    "    confs = torch.cat(confs).numpy()\n",
    "    return gts, preds, confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82713fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.12it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  6.31it/s]\n",
      "100%|██████████| 20/20 [00:03<00:00,  6.24it/s]\n"
     ]
    }
   ],
   "source": [
    "model = model.eval()\n",
    "run_dict = {}\n",
    "for split, loader in loaders.items():\n",
    "    run_dict[split] = evaluate_model(loader) # gts, preds, confs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05ecb42",
   "metadata": {},
   "source": [
    "# Bringing in CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3abe1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_processor = failure_directions.CLIPProcessor(ds_mean=hparams['mean'], ds_std=hparams['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de747cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:04<00:00,  4.39it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.60it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.49it/s]\n"
     ]
    }
   ],
   "source": [
    "clip_features = {}\n",
    "for split, loader in loaders.items():\n",
    "    clip_features[split] = clip_processor.evaluate_clip_images(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30e1d02",
   "metadata": {},
   "source": [
    "# Fitting the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8294c050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating whitening\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:00<00:05,  1.06it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:01<00:04,  1.06it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:02<00:03,  1.06it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:03<00:02,  1.06it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:04<00:01,  1.06it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:05<00:00,  1.10it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:06<00:56,  6.30s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:01<00:06,  1.04s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:02<00:05,  1.04s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:03<00:04,  1.04s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:04<00:03,  1.04s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:05<00:02,  1.04s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:06<00:01,  1.01s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:06<00:00,  1.02it/s]\u001b[A\n",
      " 20%|██        | 2/10 [00:13<00:53,  6.64s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:01<00:06,  1.04s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:02<00:05,  1.05s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:03<00:04,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:04<00:03,  1.05s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:05<00:02,  1.05s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:06<00:01,  1.02s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:07<00:00,  1.01s/it]\u001b[A\n",
      " 30%|███       | 3/10 [00:20<00:47,  6.83s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:00<00:05,  1.06it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:01<00:04,  1.06it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:02<00:03,  1.06it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:03<00:02,  1.07it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:04<00:01,  1.06it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:05<00:00,  1.08it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:06<00:00,  1.10it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:26<00:39,  6.65s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:01<00:06,  1.07s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:02<00:05,  1.07s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:03<00:04,  1.07s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:04<00:03,  1.07s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:05<00:02,  1.07s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:06<00:01,  1.04s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:07<00:00,  1.03s/it]\u001b[A\n",
      " 50%|█████     | 5/10 [00:33<00:34,  6.86s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:01<00:06,  1.05s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:02<00:05,  1.05s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:03<00:04,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:04<00:03,  1.05s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:05<00:02,  1.05s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:06<00:01,  1.02s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:07<00:00,  1.01s/it]\u001b[A\n",
      " 60%|██████    | 6/10 [00:40<00:27,  6.92s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:00<00:05,  1.10it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:01<00:04,  1.10it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:02<00:03,  1.10it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:03<00:02,  1.10it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:04<00:01,  1.10it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:05<00:00,  1.12it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:06<00:00,  1.15it/s]\u001b[A\n",
      " 70%|███████   | 7/10 [00:46<00:19,  6.65s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:00<00:05,  1.13it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:01<00:04,  1.14it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:02<00:03,  1.13it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:03<00:02,  1.13it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:04<00:01,  1.13it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:05<00:00,  1.19it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:05<00:00,  1.22it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [00:52<00:12,  6.37s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:00<00:05,  1.04it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:01<00:04,  1.04it/s]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:02<00:03,  1.04it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:03<00:02,  1.04it/s]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:04<00:01,  1.04it/s]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:05<00:00,  1.09it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:06<00:00,  1.11it/s]\u001b[A\n",
      " 90%|█████████ | 9/10 [00:59<00:06,  6.35s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:01<00:06,  1.01s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:02<00:05,  1.01s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:03<00:04,  1.01s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:04<00:03,  1.01s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:05<00:02,  1.01s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:05<00:00,  1.03it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:06<00:00,  1.06it/s]\u001b[A\n",
      "100%|██████████| 10/10 [01:05<00:00,  6.57s/it]\n"
     ]
    }
   ],
   "source": [
    "svm_fitter = failure_directions.SVMFitter()\n",
    "svm_fitter.set_preprocess(clip_features['train'])\n",
    "val_gts, val_preds, _ = run_dict['val']\n",
    "cv_scores = svm_fitter.fit(preds=val_preds, ys=val_gts, latents=clip_features['val'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "264dfc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.36it/s]\n",
      "100%|██████████| 10/10 [00:07<00:00,  1.36it/s]\n",
      "100%|██████████| 10/10 [00:07<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "svm_predictions = {}\n",
    "svm_decision_values = {}\n",
    "for split, loader in loaders.items():\n",
    "    gts_, _, _ = run_dict[split]\n",
    "    mask, dv = svm_fitter.predict(ys=gts_, latents=clip_features[split], compute_metrics=False)\n",
    "    svm_predictions[split] = mask\n",
    "    svm_decision_values[split] = dv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccb5bb4",
   "metadata": {},
   "source": [
    "## Captioning our failure modes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "793b3fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from failure_directions.src.clip_utils import get_caption_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fe8b88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excluding plott hound\n",
      "excluding vizsla\n",
      "excluding norwich terrier\n",
      "excluding rottweiler\n",
      "excluding belgian sheepdog\n",
      "excluding soft-coated wheaten terrier\n",
      "excluding pekinese\n",
      "excluding blenheim spaniel\n",
      "excluding german short-haired pointer\n",
      "excluding malamute\n",
      "excluding liver-spotted dalmatian\n",
      "excluding ibizan hound\n",
      "excluding black-and-tan coonhound\n",
      "excluding black-and-tan coonhound\n",
      "excluding rhodesian ridgeback\n",
      "excluding brabancon griffon\n",
      "excluding old english sheepdog\n",
      "excluding curly-coated retriever\n",
      "excluding appenzeller\n",
      "excluding bullterrier\n",
      "excluding coonhound\n",
      "excluding seizure-alert dog\n",
      "excluding clumber\n",
      "excluding dandie dinmont\n",
      "excluding bedlington terrier\n",
      "excluding housedog\n",
      "excluding leonberg\n",
      "excluding american staffordshire terrier\n",
      "excluding weimaraner\n",
      "excluding doberman\n",
      "excluding staffordshire bullterrier\n",
      "excluding staffordshire bullterrier\n",
      "excluding bouvier des flandres\n",
      "excluding bouvier des flandres\n",
      "excluding bouvier des flandres\n",
      "excluding smooth-haired fox terrier\n",
      "excluding sennenhunde\n",
      "excluding bluetick\n",
      "excluding entlebucher\n",
      "excluding great pyrenees\n",
      "excluding shih-tzu\n",
      "excluding wire-haired fox terrier\n",
      "excluding coondog\n",
      "excluding flat-coated retriever\n",
      "excluding shetland sheepdog\n",
      "excluding lapdog\n",
      "excluding montagu's harrier\n",
      "excluding band-tailed pigeon\n",
      "excluding green-tailed towhee\n",
      "excluding sphenisciform seabird\n",
      "excluding sphenisciform seabird\n",
      "excluding long-eared owl\n",
      "excluding sinornis\n",
      "excluding red-breasted snipe\n",
      "excluding black-fronted bush shrike\n",
      "excluding painted sandgrouse\n",
      "excluding white-headed stilt\n",
      "excluding ivorybill\n",
      "excluding gaviiform seabird\n",
      "excluding gaviiform seabird\n",
      "excluding red-backed sandpiper\n",
      "excluding fig-bird\n",
      "excluding new zealand wren\n",
      "excluding moa\n",
      "excluding white-rumped shrike\n",
      "excluding rhode island red\n",
      "excluding caprimulgiform bird\n",
      "excluding oystercatcher\n",
      "excluding pallas's sandgrouse\n",
      "excluding pallas's sandgrouse\n",
      "excluding ring-necked parakeet\n",
      "excluding red-breasted sapsucker\n",
      "excluding red-shafted flicker\n",
      "excluding dark-eyed junco\n",
      "excluding giant moa\n",
      "excluding parula warbler\n",
      "excluding procellariiform seabird\n",
      "excluding procellariiform seabird\n",
      "excluding accipitriformes\n",
      "excluding clark's nutcracker\n",
      "excluding black-necked grebe\n",
      "excluding homing pigeon\n",
      "excluding audubon's warbler\n",
      "excluding eastern meadowlark\n",
      "excluding yellow-crowned night heron\n",
      "excluding currawong\n",
      "excluding thick-billed murre\n",
      "excluding protoavis\n",
      "excluding mother carey's chicken\n",
      "excluding clay-colored robin\n",
      "excluding yellow-bellied sapsucker\n",
      "excluding falcon-gentle\n",
      "excluding tyrannid\n",
      "excluding audubon's caracara\n",
      "excluding euopean hoopoe\n",
      "excluding white-crowned sparrow\n",
      "excluding meadowlark\n",
      "excluding aegypiidae\n",
      "excluding archilochus colubris\n",
      "excluding archilochus colubris\n",
      "excluding black-capped chickadee\n",
      "excluding columbiform bird\n",
      "excluding rough-legged hawk\n",
      "excluding yellow-shafted flicker\n",
      "excluding spotted antbird\n",
      "excluding chuck-will's-widow\n",
      "excluding bewick's swan\n",
      "excluding saddlebill\n",
      "excluding wilson's warbler\n",
      "excluding grassfinch\n",
      "excluding yellow-breasted bunting\n",
      "excluding white-tailed kite\n",
      "excluding red-breasted merganser\n",
      "excluding roadrunner\n",
      "excluding pied-billed grebe\n",
      "excluding sulphur-crested cockatoo\n",
      "excluding cassin's kingbird\n",
      "excluding bushtit\n",
      "excluding flycatching warbler\n",
      "excluding barrow's goldeneye\n",
      "excluding sharp-tailed grouse\n",
      "excluding greyhen\n",
      "excluding long-billed marsh wren\n",
      "excluding streptopelia turtur\n",
      "excluding streptopelia turtur\n",
      "excluding white-breasted nuthatch\n",
      "excluding wilson's phalarope\n",
      "excluding red-breasted nuthatch\n",
      "excluding adelie\n",
      "excluding whydah\n",
      "excluding rose-colored starling\n",
      "excluding red-legged partridge\n",
      "excluding gold-crowned kinglet\n",
      "excluding black-necked stilt\n",
      "excluding western meadowlark\n",
      "excluding cream-colored courser\n",
      "excluding antbird\n",
      "excluding blue-headed vireo\n",
      "excluding white-chinned petrel\n",
      "excluding quack-quack\n",
      "excluding pelecaniform seabird\n",
      "excluding pelecaniform seabird\n",
      "excluding ibero-mesornis\n",
      "excluding sandgrouse\n",
      "excluding anseriform bird\n",
      "excluding tiercel\n",
      "excluding pin-tailed sandgrouse\n",
      "excluding pin-tailed sandgrouse\n",
      "excluding apodiform bird\n",
      "excluding vermillion flycatcher\n",
      "excluding podicipitiform seabird\n",
      "excluding podicipitiform seabird\n",
      "excluding honeycreeper\n",
      "excluding red-winged blackbird\n",
      "excluding bullock's oriole\n",
      "excluding cooper's hawk\n",
      "excluding black-winged stilt\n",
      "excluding afropavo\n",
      "excluding white-throated sparrow\n",
      "excluding moorcock\n",
      "excluding wilson's snipe\n",
      "excluding red-necked grebe\n",
      "excluding black-footed albatross\n",
      "excluding black-crowned night heron\n",
      "excluding white-bellied swallow\n",
      "excluding resplendent quetzel\n",
      "excluding red-eyed vireo\n",
      "excluding black-billed cuckoo\n",
      "excluding seabird\n",
      "excluding greylag\n",
      "excluding moorhen\n",
      "excluding yellow-breasted chat\n",
      "excluding blackburn\n",
      "excluding red-shouldered hawk\n",
      "excluding black-backed gull\n",
      "excluding swallow-tailed kite\n",
      "excluding woodhewer\n",
      "excluding corncrake\n",
      "excluding ern\n",
      "excluding shorebird\n",
      "excluding ruby-crowned kinglet\n",
      "excluding ring-necked pheasant\n",
      "excluding wren-tit\n",
      "excluding minivan\n",
      "excluding minicab\n",
      "excluding subcompact\n",
      "excluding used-car\n",
      "excluding minicar\n",
      "excluding hatchback\n",
      "excluding hardtop\n",
      "excluding ski-plane\n",
      "excluding widebody aircraft\n",
      "excluding jetliner\n",
      "excluding jumbojet\n",
      "excluding airbus\n",
      "excluding narrowbody aircraft\n",
      "excluding fanjet\n",
      "excluding double-prop\n",
      "excluding twinjet\n",
      "excluding propjet\n",
      "excluding minivan\n",
      "excluding blockade-runner\n",
      "excluding nuclear-powered ship\n",
      "excluding guided missile frigate\n",
      "excluding side-wheeler\n",
      "excluding guided missile cruiser\n",
      "excluding sternwheeler\n",
      "excluding torpedo-boat destroyer\n",
      "excluding pt boat\n",
      "excluding cattleship\n",
      "excluding gas-turbine ship\n",
      "excluding supertanker\n",
      "excluding mailboat\n",
      "excluding minesweeper\n",
      "excluding man-of-war\n",
      "excluding car-ferry\n",
      "excluding minelayer\n",
      "excluding eastern narrow-mouthed toad\n",
      "excluding fire-bellied toad\n",
      "excluding yosemite toad\n",
      "excluding canyon treefrog\n",
      "excluding leptodactylid frog\n",
      "excluding lowland burrowing treefrog\n",
      "excluding lowland burrowing treefrog\n",
      "excluding western narrow-mouthed toad\n",
      "excluding cascades frog\n",
      "excluding plains spadefoot\n",
      "excluding wood-frog\n",
      "excluding liopelma hamiltoni\n",
      "excluding liopelma hamiltoni\n",
      "excluding jaguarundi\n",
      "excluding lippizan\n",
      "excluding three-year-old horse\n",
      "excluding przewalski's horse\n",
      "excluding trotting horse\n",
      "excluding tennessee walker\n",
      "excluding gee-gee\n",
      "excluding carthorse\n",
      "excluding mudder\n",
      "excluding stablemate\n",
      "excluding broodmare\n",
      "excluding warrigal\n",
      "excluding packhorse\n",
      "excluding two-year-old horse\n",
      "excluding racehorse\n",
      "excluding appaloosa\n",
      "excluding dik-dik\n",
      "excluding gazella subgutturosa\n",
      "excluding black-tailed deer\n",
      "excluding pere david's deer\n",
      "excluding pere david's deer\n",
      "excluding mountain nyala\n",
      "excluding harnessed antelope\n",
      "excluding thomson's gazelle\n",
      "excluding blackbuck\n",
      "excluding waterbuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "bird\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 2/11 [00:00<00:00, 12.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automobile\n",
      "airplane\n",
      "truck\n",
      "ship\n",
      "frog\n",
      "cat\n",
      "horse\n",
      "deer\n",
      "reference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 50.66it/s]\n"
     ]
    }
   ],
   "source": [
    "captions = failure_directions.get_caption_set('CIFAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad1b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airplane a photo of a airplane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 23.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.08it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automobile a photo of a automobile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 22.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.47it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bird a photo of a bird\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:09<00:00, 26.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 86.09it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "selected_captions = []\n",
    "for target_c in range(10):\n",
    "    target_c_name = test_ds.classes[target_c]\n",
    "    caption_set = captions[target_c_name]['all']\n",
    "    reference = captions['reference'][target_c]\n",
    "    print(target_c_name, reference)\n",
    "    decisions, _ = clip_processor.get_caption_scores(captions=caption_set,\n",
    "                                                     reference_caption=reference,\n",
    "                                                     svm_fitter=svm_fitter,\n",
    "                                                     target_c=target_c)\n",
    "    selected_captions.append((\n",
    "        caption_set[np.argmin(decisions)],\n",
    "        caption_set[np.argmax(decisions)], decisions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f57ce1e",
   "metadata": {},
   "source": [
    "## Visualize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7599fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_images(ds, ds_indices, ds_values, K=10, title=\"\"):\n",
    "    fig, ax = plt.subplots(1, K, figsize=(K*2, 3))\n",
    "    for i in range(K):\n",
    "        idx = ds_indices[i]\n",
    "        ax[i].imshow(TOIMAGE(ds[idx][0]))\n",
    "        ax[i].axis(False)\n",
    "        ax[i].set_title(f\"{ds_values[i]:0.3f}\")\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "gts = run_dict['test'][0]\n",
    "for c in range(10):\n",
    "    print(\"---\")\n",
    "    selected_caps = selected_captions[c]\n",
    "    mask = gts == c\n",
    "    masked_indices = np.arange(len(mask))[mask]\n",
    "    dv = svm_decision_values['test'][mask]\n",
    "    bottom_dv = np.argsort(dv)\n",
    "    top_dv = bottom_dv[::-1]\n",
    "    for order_name, order, cap in (\n",
    "        ('bottom', bottom_dv, selected_caps[0]),\n",
    "        (\"top\", top_dv, selected_caps[1]),\n",
    "    ):\n",
    "        vals = dv[order]\n",
    "        visualize_images(test_ds, masked_indices[order], vals, title=cap)\n",
    "        print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc6495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
