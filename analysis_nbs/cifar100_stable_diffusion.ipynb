{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1550954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/home/saachij/conda_envs/ffcv_cfs/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "sys.path.append('../failure_directions')\n",
    "import torch\n",
    "import torchvision\n",
    "import failure_directions\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.cuda.amp import autocast\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import failure_directions.src.svm_utils as svm_utils\n",
    "import failure_directions.src.visualization_utils as viz_utils\n",
    "import failure_directions.src.ds_utils as ds_utils\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from failure_directions.src.label_maps import CLASS_DICT\n",
    "import pickle as pkl\n",
    "from torchvision.datasets.folder import pil_loader\n",
    "import failure_directions.src.pytorch_datasets as pytorch_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12da024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "BLUE = sns.color_palette(\"tab10\")[0]\n",
    "RED = sns.color_palette(\"tab10\")[3]\n",
    "ORANGE = sns.color_palette(\"tab10\")[1]\n",
    "BROWN = sns.color_palette(\"tab10\")[5]\n",
    "GRAY = sns.color_palette(\"tab10\")[7]\n",
    "GREEN = sns.color_palette(\"tab10\")[2]\n",
    "\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 12,\n",
    "          'figure.figsize': (5, 3),\n",
    "         'axes.labelsize': 14,\n",
    "         'axes.titlesize':16,\n",
    "         'xtick.labelsize':14,\n",
    "         'ytick.labelsize':14}\n",
    "pylab.rcParams.update(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894e1323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/home/saachij/src/failure-directions/failure_directions\n",
      "-----------train_metrics--------------\n",
      "{'Confusion Matrix': array([[   41,    34],\n",
      "       [ 6135, 10806]]),\n",
      " 'Model Accuracy': 0.9955923836389281,\n",
      " 'SVM Accuracy': 0.637458860874176,\n",
      " 'SVM Balanced Accuracy': 0.5922637581825256}\n",
      "-----------val_metrics--------------\n",
      "{'Confusion Matrix': array([[2532,  528],\n",
      "       [1286, 5654]]),\n",
      " 'Model Accuracy': 0.694,\n",
      " 'SVM Accuracy': 0.8185999989509583,\n",
      " 'SVM Balanced Accuracy': 0.8210741877555847}\n",
      "-----------test_metrics--------------\n",
      "{'Confusion Matrix': array([[2058,  979],\n",
      "       [1748, 5215]]),\n",
      " 'Model Accuracy': 0.6963,\n",
      " 'SVM Accuracy': 0.7272999882698059,\n",
      " 'SVM Balanced Accuracy': 0.7133005857467651}\n",
      "-----------unlabeled_metrics--------------\n",
      "{'Confusion Matrix': array([[ 4157,  2068],\n",
      "       [ 3495, 10280]]),\n",
      " 'Model Accuracy': 0.68875,\n",
      " 'SVM Accuracy': 0.7218499779701233,\n",
      " 'SVM Balanced Accuracy': 0.7070353329181671}\n",
      "Using default os_cache: False\n",
      "Using default quasi_random: True\n",
      "Using default val_aug: None\n",
      "Using default loss_vec_file: None\n",
      "Using default indices_file: None\n",
      "Using default val_beton: None\n",
      "Using default unlabeled_beton: None\n",
      "Using default loss_upweight: 5\n",
      "Using default bce: False\n",
      "Using default cmnist: False\n",
      "\n",
      "-----------CONFIG--------------\n",
      "{   'arch': 'resnet18',\n",
      "    'arch_type': 'cifar_resnet',\n",
      "    'batch_size': 100,\n",
      "    'bce': False,\n",
      "    'cmnist': False,\n",
      "    'drop_last': False,\n",
      "    'imgsz': 32,\n",
      "    'indices_file': None,\n",
      "    'loss_upweight': 5,\n",
      "    'loss_vec_file': None,\n",
      "    'mean': [125.307, 122.961, 113.8575],\n",
      "    'num_classes': 20,\n",
      "    'num_workers': 1,\n",
      "    'os_cache': False,\n",
      "    'quasi_random': True,\n",
      "    'shuffle': False,\n",
      "    'std': [51.5865, 50.847, 51.255],\n",
      "    'test_beton': 'supercifar100/supercifar100_test.beton',\n",
      "    'train_aug': 'cifar_train_aug',\n",
      "    'train_beton': 'supercifar100/supercifar100_train.beton',\n",
      "    'train_img_decoder': 'simple',\n",
      "    'training': {   'epochs': 35,\n",
      "                    'lr': 0.5,\n",
      "                    'lr_scheduler': {'lr_peak_epoch': 5, 'type': 'cyclic'},\n",
      "                    'optimizer': {'momentum': 0.9, 'weight_decay': 0.0005}},\n",
      "    'unlabeled_beton': None,\n",
      "    'val_aug': None,\n",
      "    'val_beton': None,\n",
      "    'val_img_decoder': 'simple'}\n",
      "{'training_args': {'epochs': 35, 'lr': 0.5, 'optimizer': {'momentum': 0.9, 'weight_decay': 0.0005}, 'lr_scheduler': {'type': 'cyclic', 'lr_peak_epoch': 5}, 'iters_per_epoch': 33}, 'epoch': 34, 'training_metrics': {'loss': 0.029270435203657005, 'acc': 0.9939630681818182}, 'val_metrics': {'loss': 1.3071045623779296, 'acc': 0.6939999999046326}}\n",
      "Pulling val from train\n",
      "Pulling unlabeled from train\n",
      "getting train loader\n",
      "getting val loader\n",
      "getting unlabeled loader\n",
      "getting test loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:03<00:00, 46.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9947108626365662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 83.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6940000057220459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 62.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6963000297546387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 124.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6887500286102295\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs\n",
      "{'training_args': {'epochs': 35, 'lr': 0.5, 'optimizer': {'momentum': 0.9, 'weight_decay': 0.0005}, 'lr_scheduler': {'type': 'cyclic', 'lr_peak_epoch': 5}, 'iters_per_epoch': 33}, 'epoch': 34, 'training_metrics': {'loss': 0.029270435203657005, 'acc': 0.9939630681818182}, 'val_metrics': {'loss': 1.3071045623779296, 'acc': 0.6939999999046326}}\n"
     ]
    }
   ],
   "source": [
    "#Load SVM Model\n",
    "beton_root = \"/mnt/cfs/projects/correlated_errors/betons\"\n",
    "experiment_root = \"/mnt/cfs/projects/correlated_errors/experiments/spurious_cifar100/unlabeled_1_4_new_spurious_norm\"\n",
    "\n",
    "svm_name = \"svm_spurious_unlabeled_normalized\"\n",
    "name = os.path.join(experiment_root, f\"svm_checkpoints/{svm_name}.pt\") # SVM output file\n",
    "svm_model_name = os.path.join(experiment_root, f\"svm_checkpoints/{svm_name}_model.pkl\") # SVM output file\n",
    "model_root = os.path.join(experiment_root, \"models\")\n",
    "model_ckpt = os.path.join(model_root, \"spurious_supercifar100_unlabeled/version_0/checkpoints/checkpoint_last.pt\")\n",
    "loss_upweight_root = os.path.join(experiment_root, \"loss_vec_files\")\n",
    "subset_root = os.path.join(experiment_root, \"subset_index_files\")\n",
    "\n",
    "%cd ../failure_directions\n",
    "processor = viz_utils.SVMProcessor(name, root=beton_root, checkpoint_path=model_ckpt, get_unlabeled=True)\n",
    "classes_to_drop = torch.load(processor.metrics['args']['indices_file'])['classes_to_drop']\n",
    "%cd ../analysis_nbs\n",
    "svm_model = processor._build_model(model_ckpt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7599cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.pytorch_datasets as pytorch_datasets\n",
    "ds = pytorch_datasets.SuperCIFAR100(root=\"/mnt/nfs/home/saachij/datasets/cifar100\", train=False)\n",
    "class_names = np.array(ds.classes)\n",
    "subclass_names = []\n",
    "# asterisk subclass_names\n",
    "for c, n in enumerate(ds.subclasses):\n",
    "    name = ' '.join(n.split('_'))\n",
    "    if c in classes_to_drop:\n",
    "        name += \"*\"\n",
    "    subclass_names.append(name)\n",
    "subclass_names = np.array(subclass_names)\n",
    "singular_class_names = ['aquatic mammal', 'fish', 'flower', 'food container', 'fruit or vegetable', 'household electrical device', 'household furniture', 'insect', 'large carnivore', 'large man-made outdoor thing', 'large natural outdoor scene', 'large omnivores and herbivore', 'medium-sized mammal', 'non-insect invertebrate', 'person', 'reptile', 'small mammal', 'tree', 'standard vehicle', 'specialized vehicle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79901106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea5bc340",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'test'\n",
    "test_dv = processor.metrics[f'{split}_metrics']['decision_values']\n",
    "test_confs = processor.run_dict[split]['confs']\n",
    "test_superclass = processor.metrics[f'{split}_metrics']['classes'] # 0 if female, 1 if male\n",
    "test_subclass = processor.metrics[f'{split}_metrics']['spuriouses'] #1 if blond, 2 if black hair, 0 if neither\n",
    "test_problematic = np.in1d(test_subclass, classes_to_drop)\n",
    "test_pred_correct = processor.metrics[f'{split}_metrics']['ypred']\n",
    "test_correct = processor.metrics[f'{split}_metrics']['ytrue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64ecf250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/home/saachij/src/failure-directions/failure_directions\n",
      "Using default os_cache: False\n",
      "Using default quasi_random: True\n",
      "Using default val_aug: None\n",
      "Using default loss_vec_file: None\n",
      "Using default indices_file: None\n",
      "Using default val_beton: None\n",
      "Using default unlabeled_beton: None\n",
      "Using default loss_upweight: 5\n",
      "Using default bce: False\n",
      "Using default cmnist: False\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs\n"
     ]
    }
   ],
   "source": [
    "from failure_directions.src.config_parsing import ffcv_read_check_override_config\n",
    "import yaml\n",
    "hparams = processor.hparams\n",
    "%cd ../failure_directions\n",
    "with open(processor.metrics['args']['config'], 'r') as file:\n",
    "    fresh_hparams = yaml.safe_load(file)\n",
    "fresh_hparams = ffcv_read_check_override_config(fresh_hparams)\n",
    "%cd ../analysis_nbs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0780f44",
   "metadata": {},
   "source": [
    "## Get SVM Directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c27e0e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:54<00:00,  3.15it/s]\n",
      "100%|██████████| 100/100 [00:32<00:00,  3.09it/s]\n",
      "100%|██████████| 100/100 [00:32<00:00,  3.09it/s]\n",
      "100%|██████████| 200/200 [01:04<00:00,  3.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get big CLIP features\n",
    "clip_processor = failure_directions.CLIPProcessor(ds_mean=hparams['mean'], ds_std=hparams['std'], arch='ViT-L/14')\n",
    "clip_features = {}\n",
    "for split, loader in processor.loaders.items():\n",
    "    clip_features[split] = clip_processor.evaluate_clip_images(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15b9e97b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No whitening\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.74it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.87it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 12.11it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:00<00:11,  1.72it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.89it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.90it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.72it/s]\u001b[A\n",
      " 10%|█         | 2/20 [00:01<00:10,  1.69it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.33it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.61it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.70it/s]\u001b[A\n",
      " 15%|█▌        | 3/20 [00:01<00:10,  1.68it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.16it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.23it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.21it/s]\u001b[A\n",
      " 20%|██        | 4/20 [00:02<00:09,  1.64it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.48it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.40it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.77it/s]\u001b[A\n",
      " 25%|██▌       | 5/20 [00:03<00:09,  1.65it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.24it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.33it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.40it/s]\u001b[A\n",
      " 30%|███       | 6/20 [00:03<00:08,  1.64it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.29it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.37it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.51it/s]\u001b[A\n",
      " 35%|███▌      | 7/20 [00:04<00:07,  1.64it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.29it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.24it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.43it/s]\u001b[A\n",
      " 40%|████      | 8/20 [00:04<00:07,  1.63it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 10.86it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.26it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.50it/s]\u001b[A\n",
      " 45%|████▌     | 9/20 [00:05<00:06,  1.63it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.55it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.49it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.73it/s]\u001b[A\n",
      " 50%|█████     | 10/20 [00:06<00:06,  1.64it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.57it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.67it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.78it/s]\u001b[A\n",
      " 55%|█████▌    | 11/20 [00:06<00:05,  1.65it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.51it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.57it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.65it/s]\u001b[A\n",
      " 60%|██████    | 12/20 [00:07<00:04,  1.65it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.52it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.45it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.56it/s]\u001b[A\n",
      " 65%|██████▌   | 13/20 [00:07<00:04,  1.65it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.36it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.33it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.52it/s]\u001b[A\n",
      " 70%|███████   | 14/20 [00:08<00:03,  1.65it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.62it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.44it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.92it/s]\u001b[A\n",
      " 75%|███████▌  | 15/20 [00:09<00:03,  1.66it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.86it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.76it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.76it/s]\u001b[A\n",
      " 80%|████████  | 16/20 [00:09<00:02,  1.66it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.71it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.72it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.71it/s]\u001b[A\n",
      " 85%|████████▌ | 17/20 [00:10<00:01,  1.66it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 12.07it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 12.18it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 12.44it/s]\u001b[A\n",
      " 90%|█████████ | 18/20 [00:10<00:01,  1.69it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.84it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.62it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.78it/s]\u001b[A\n",
      " 95%|█████████▌| 19/20 [00:11<00:00,  1.69it/s]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:00<00:00, 11.72it/s]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:00<00:00, 11.65it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:00<00:00, 11.92it/s]\u001b[A\n",
      "100%|██████████| 20/20 [00:12<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "svm_fitter = failure_directions.SVMFitter()\n",
    "svm_fitter.set_preprocess()\n",
    "val_gts, val_preds = processor.run_dict['val']['ys'], processor.run_dict['val']['preds']\n",
    "cv_scores = svm_fitter.fit(preds=val_preds, ys=val_gts, latents=clip_features['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0295b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = \"cifar100_large_directions\"\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "for i in range(len(svm_fitter.clfs)):\n",
    "    d = svm_fitter.clfs[i].coef_.squeeze(0)\n",
    "    np.save(f\"{directory}/dir{i}.npy\", d/np.linalg.norm(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34ab92f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 60536.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aquatic mammal\n",
      "fish\n",
      "flower\n",
      "food container\n",
      "fruit or vegetable\n",
      "household electrical device\n",
      "household furniture\n",
      "insect\n",
      "large carnivore\n",
      "large man-made outdoor thing\n",
      "large natural outdoor scene\n",
      "large omnivores and herbivore\n",
      "medium-sized mammal\n",
      "non-insect invertebrate\n",
      "person\n",
      "reptile\n",
      "small mammal\n",
      "tree\n",
      "standard vehicle\n",
      "specialized vehicle\n",
      "reference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from failure_directions.src.clip_utils import get_caption_set\n",
    "captions = failure_directions.get_caption_set('CIFAR100')\n",
    "ref_captions = clip_processor.evaluate_clip_captions(captions['reference'])\n",
    "np.save(f\"{directory}/ref_captions.npy\", ref_captions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81dd5e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['apple', 'aquarium fish', 'baby*', 'bear*', 'beaver*', 'bed',\n",
       "       'bee', 'beetle', 'bicycle', 'bottle', 'bowl*', 'boy', 'bridge*',\n",
       "       'bus*', 'butterfly', 'camel', 'can', 'castle', 'caterpillar*',\n",
       "       'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach',\n",
       "       'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin',\n",
       "       'elephant', 'flatfish', 'forest*', 'fox', 'girl', 'hamster',\n",
       "       'house', 'kangaroo*', 'keyboard', 'lamp*', 'lawn mower', 'leopard',\n",
       "       'lion', 'lizard*', 'lobster*', 'man', 'maple tree', 'motorcycle',\n",
       "       'mountain', 'mouse', 'mushroom*', 'oak tree', 'orange', 'orchid*',\n",
       "       'otter', 'palm tree', 'pear', 'pickup truck', 'pine tree', 'plain',\n",
       "       'plate', 'poppy', 'porcupine', 'possum*', 'rabbit', 'raccoon',\n",
       "       'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark*', 'shrew',\n",
       "       'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel*',\n",
       "       'streetcar*', 'sunflower', 'sweet pepper', 'table*', 'tank',\n",
       "       'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
       "       'tulip', 'turtle', 'wardrobe', 'whale', 'willow tree*', 'wolf',\n",
       "       'woman', 'worm'], dtype='<U13')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclass_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af206505",
   "metadata": {},
   "source": [
    "## Read the generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f5e794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.stable_diffusion_utils as sd_utils\n",
    "from src.stable_diffusion_utils import DiffDataset\n",
    "\n",
    "images_path = \"/mnt/cfs/home/saachij/src/stable-diffusion/cifar100_images\"\n",
    "path_dict = sd_utils.get_path_dict(images_path, num_classes=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9b13ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from failure_directions.src.decoders_and_transforms import PyTranslate, PyCutOut\n",
    "hparams = processor.hparams\n",
    "\n",
    "fill_color = tuple(map(int, hparams['mean']))\n",
    "\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=np.array(hparams['mean'])/255, std=np.array(hparams['std'])/255)])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    PyTranslate(2),\n",
    "    PyCutOut(4, fill_color),\n",
    "    base_transform\n",
    "])\n",
    "\n",
    "# For visualization\n",
    "INV_NORM = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [255/x for x in hparams['std']]),\n",
    "                                transforms.Normalize(mean = [-x /255 for x in hparams['mean']],\n",
    "                                                     std = [ 1., 1., 1. ])])\n",
    "TOIMAGE = transforms.Compose([INV_NORM, transforms.ToPILImage()])\n",
    "resize_base_transform = transforms.Compose([base_transform, transforms.Resize((32, 32))])\n",
    "resize_train_transform = transforms.Compose([train_transform, transforms.Resize((32, 32))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ce0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            gts, preds, confs = [], [], []\n",
    "            for x, y in tqdm(loader):\n",
    "                x = x.cuda()\n",
    "                logits = model(x)\n",
    "                gts.append(y.cpu())\n",
    "                preds.append(logits.argmax(-1).cpu())\n",
    "                softmax_logits = nn.Softmax(dim=-1)(logits)\n",
    "                confs.append(softmax_logits[torch.arange(logits.shape[0]), y].cpu())\n",
    "    gts = torch.cat(gts)\n",
    "    preds = torch.cat(preds)\n",
    "    confs = torch.cat(confs)\n",
    "    return gts, preds, confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aad667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 20.80it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 20.75it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 20.89it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 20.82it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 21.27it/s]\n",
      "100%|██████████| 24/24 [00:01<00:00, 20.39it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 20.75it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 20.97it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 21.43it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 21.11it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 20.85it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 19.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8290598392486572 0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 20.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.017094017937779427 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 21.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.811965823173523 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 21.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.4871794879436493 0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 21.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.4615384638309479 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 20.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.10256410390138626 0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 20.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.5726495981216431 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 21.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.2222222238779068 0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 21.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.18803419172763824 0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 21.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.9487179517745972 0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 20.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.4615384638309479 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 21.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0.5982906222343445 0.672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 20.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0.07692307978868484 0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 21.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0.0 0.592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 20.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0.9145299196243286 0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 21.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0.04273504391312599 0.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 20.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.18803419172763824 0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 21.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0.470085471868515 0.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 20.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.9230769276618958 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 21.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.25641027092933655 0.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# See relative accuracies\n",
    "def get_diff_predictions(flip_name, intensity,target_class=None):\n",
    "    base_ds = DiffDataset(path_dict, flip_name=flip_name, intensity=intensity, transform=resize_base_transform, num_classes=20)\n",
    "    base_loader = torch.utils.data.DataLoader(base_ds, batch_size=100, shuffle=False, drop_last=False)\n",
    "    gts, preds, confs = evaluate_model(svm_model, base_loader)\n",
    "    if target_class is not None:\n",
    "        mask = gts == target_class\n",
    "        gts, preds, confs = gts[mask], preds[mask], confs[mask]\n",
    "    return gts, preds, confs, (gts==preds).float().mean().item()\n",
    "\n",
    "intensities = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "base_acc = get_diff_predictions(flip_name=\"flip\", intensity=0)[3]\n",
    "flip_accs = [get_diff_predictions(flip_name=\"flip\", intensity=u)[3] for u in intensities]\n",
    "no_flip_accs = [get_diff_predictions(flip_name=\"no_flip\", intensity=u)[3] for u in intensities]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "sns.lineplot(x=intensities, y=flip_accs, label='Hard Direction', ax=ax)\n",
    "sns.lineplot(x=intensities, y=no_flip_accs, label='Easy Direction', ax=ax)\n",
    "sns.lineplot(x=intensities, y=[base_acc]*len(intensities), label='Neutral Images', ax=ax)\n",
    "ax.set_xlabel(\"Alpha\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "base_accs = []\n",
    "orig_accs = []\n",
    "for c in range(20):\n",
    "    base_acc = get_diff_predictions(flip_name=\"flip\", intensity=0, target_class=c)[3]\n",
    "    orig_acc = (test_correct[test_superclass == c]).mean()\n",
    "    print(c, base_acc, orig_acc)\n",
    "    base_accs.append(base_acc)\n",
    "    orig_accs.append(orig_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4244c980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "for c in range(20):\n",
    "    print(len(path_dict[c]['flip'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a324ac",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95272a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bc68f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperCIFAR100Wrapper:\n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y, _ = self.ds[idx]\n",
    "        return x, y\n",
    "\n",
    "bsz = fresh_hparams['batch_size']\n",
    "ds_root = \"/mnt/cfs/datasets/cifar100\"\n",
    "\n",
    "orig_train_ds = SuperCIFAR100Wrapper(pytorch_datasets.SuperCIFAR100(root=ds_root, train=True, transform=base_transform))\n",
    "aug_train_ds = SuperCIFAR100Wrapper(pytorch_datasets.SuperCIFAR100(root=ds_root, train=True, transform=train_transform))\n",
    "test_ds = SuperCIFAR100Wrapper(pytorch_datasets.SuperCIFAR100(root=ds_root, train=False, transform=base_transform))\n",
    "\n",
    "val_indices = processor.indices_dict['val_indices']\n",
    "train_indices = processor.indices_dict['train_indices']\n",
    "\n",
    "train_ds = torch.utils.data.Subset(aug_train_ds, train_indices)\n",
    "val_ds = torch.utils.data.Subset(orig_train_ds, val_indices)\n",
    "no_aug_train_ds = torch.utils.data.Subset(orig_train_ds, train_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=bsz, shuffle=True, drop_last=True)\n",
    "no_shuffle_train_loader = torch.utils.data.DataLoader(train_ds, batch_size=bsz, shuffle=False, drop_last=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=bsz, shuffle=False, drop_last=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=bsz, shuffle=False, drop_last=False)\n",
    "no_aug_train_loader = torch.utils.data.DataLoader(no_aug_train_ds, batch_size=bsz, shuffle=False, drop_last=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "017426b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(train_loader_, val_loader_, test_loader_, set_device=False):\n",
    "    build_fn = failure_directions.model_utils.BUILD_FUNCTIONS[hparams['arch_type']]\n",
    "    model = build_fn(hparams['arch'], hparams['num_classes'])\n",
    "    model = model.cuda()\n",
    "\n",
    "    training_args=hparams['training']\n",
    "    training_args['iters_per_epoch'] = len(train_loader_)\n",
    "    trainer = failure_directions.LightWeightTrainer(training_args=hparams['training'],\n",
    "                                                    exp_name='temp', enable_logging=False,\n",
    "                                                    bce=False, set_device=set_device)\n",
    "    trainer.fit(model, train_loader_, val_loader_)\n",
    "    return evaluate_model(model, test_loader_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c29574d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0: 100%|██████████| 33/33 [00:05<00:00,  5.52it/s, loss=2.57, acc=0.227]\n",
      "Val Epoch: 0: 100%|██████████| 20/20 [00:01<00:00, 10.60it/s, loss=3.84, acc=0.0735] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.1, Train Loss: 2.7770, Train Acc: 0.1634, Val Loss: 7.0241, Val Acc: 0.1271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1: 100%|██████████| 33/33 [00:05<00:00,  5.54it/s, loss=2.36, acc=0.266]\n",
      "Val Epoch: 1: 100%|██████████| 20/20 [00:01<00:00, 10.65it/s, loss=3.39, acc=0.0294] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.2, Train Loss: 2.4822, Train Acc: 0.2421, Val Loss: 3.1169, Val Acc: 0.1944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2: 100%|██████████| 33/33 [00:05<00:00,  5.53it/s, loss=2.22, acc=0.316]\n",
      "Val Epoch: 2: 100%|██████████| 20/20 [00:01<00:00, 10.61it/s, loss=2.03, acc=0.25]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3, Train Loss: 2.2855, Train Acc: 0.2973, Val Loss: 2.4252, Val Acc: 0.2803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3: 100%|██████████| 33/33 [00:05<00:00,  5.53it/s, loss=2.22, acc=0.303]\n",
      "Val Epoch: 3: 100%|██████████| 20/20 [00:02<00:00,  8.99it/s, loss=2.85, acc=0.0846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4, Train Loss: 2.1372, Train Acc: 0.3422, Val Loss: 2.2885, Val Acc: 0.2993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4: 100%|██████████| 33/33 [00:05<00:00,  5.51it/s, loss=2.11, acc=0.346]\n",
      "Val Epoch: 4: 100%|██████████| 20/20 [00:01<00:00, 10.56it/s, loss=1.75, acc=0.331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.5, Train Loss: 2.0549, Train Acc: 0.3629, Val Loss: 2.4322, Val Acc: 0.2890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5: 100%|██████████| 33/33 [00:05<00:00,  5.51it/s, loss=1.88, acc=0.414]\n",
      "Val Epoch: 5: 100%|██████████| 20/20 [00:01<00:00, 10.54it/s, loss=1.91, acc=0.32] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.48333333333333334, Train Loss: 1.9180, Train Acc: 0.4051, Val Loss: 2.1049, Val Acc: 0.3539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=1.78, acc=0.451]\n",
      "Val Epoch: 6: 100%|██████████| 20/20 [00:01<00:00, 10.60it/s, loss=1.52, acc=0.441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4666666666666667, Train Loss: 1.8097, Train Acc: 0.4365, Val Loss: 2.0004, Val Acc: 0.3826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=1.65, acc=0.475]\n",
      "Val Epoch: 7: 100%|██████████| 20/20 [00:01<00:00, 10.45it/s, loss=2.17, acc=0.287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.45, Train Loss: 1.6977, Train Acc: 0.4668, Val Loss: 1.9779, Val Acc: 0.3991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=1.62, acc=0.477]\n",
      "Val Epoch: 8: 100%|██████████| 20/20 [00:01<00:00, 10.32it/s, loss=1.43, acc=0.46] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.43333333333333335, Train Loss: 1.5987, Train Acc: 0.4957, Val Loss: 1.9060, Val Acc: 0.4222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=1.55, acc=0.486]\n",
      "Val Epoch: 9: 100%|██████████| 20/20 [00:01<00:00, 10.47it/s, loss=2.2, acc=0.382] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4166666666666667, Train Loss: 1.4960, Train Acc: 0.5228, Val Loss: 1.9194, Val Acc: 0.4035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=1.33, acc=0.59] \n",
      "Val Epoch: 10: 100%|██████████| 20/20 [00:01<00:00, 10.34it/s, loss=2.1, acc=0.368] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4, Train Loss: 1.3904, Train Acc: 0.5591, Val Loss: 1.8859, Val Acc: 0.4235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=1.34, acc=0.572]\n",
      "Val Epoch: 11: 100%|██████████| 20/20 [00:01<00:00, 10.43it/s, loss=2.66, acc=0.213] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3833333333333333, Train Loss: 1.3153, Train Acc: 0.5817, Val Loss: 1.9007, Val Acc: 0.4455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=1.22, acc=0.604]\n",
      "Val Epoch: 12: 100%|██████████| 20/20 [00:01<00:00, 10.49it/s, loss=2.09, acc=0.353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3666666666666667, Train Loss: 1.2449, Train Acc: 0.6045, Val Loss: 1.7262, Val Acc: 0.4716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=1.2, acc=0.59]  \n",
      "Val Epoch: 13: 100%|██████████| 20/20 [00:01<00:00, 10.50it/s, loss=1.69, acc=0.463] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.35, Train Loss: 1.1395, Train Acc: 0.6332, Val Loss: 1.6212, Val Acc: 0.5065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=1.08, acc=0.65]  \n",
      "Val Epoch: 14: 100%|██████████| 20/20 [00:01<00:00, 10.47it/s, loss=2.51, acc=0.353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.33333333333333337, Train Loss: 1.0625, Train Acc: 0.6580, Val Loss: 1.8213, Val Acc: 0.4598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=0.967, acc=0.709]\n",
      "Val Epoch: 15: 100%|██████████| 20/20 [00:01<00:00, 10.48it/s, loss=1.4, acc=0.555]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.31666666666666665, Train Loss: 0.9914, Train Acc: 0.6812, Val Loss: 1.6324, Val Acc: 0.5003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=0.826, acc=0.734]\n",
      "Val Epoch: 16: 100%|██████████| 20/20 [00:01<00:00, 10.44it/s, loss=1.42, acc=0.522] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3, Train Loss: 0.9052, Train Acc: 0.7051, Val Loss: 1.6334, Val Acc: 0.5269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=0.943, acc=0.709]\n",
      "Val Epoch: 17: 100%|██████████| 20/20 [00:01<00:00, 10.58it/s, loss=1.5, acc=0.522]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.2833333333333333, Train Loss: 0.8608, Train Acc: 0.7233, Val Loss: 1.5023, Val Acc: 0.5516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18: 100%|██████████| 33/33 [00:05<00:00,  5.50it/s, loss=0.796, acc=0.729]\n",
      "Val Epoch: 18: 100%|██████████| 20/20 [00:01<00:00, 10.53it/s, loss=1.26, acc=0.592] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.26666666666666666, Train Loss: 0.7911, Train Acc: 0.7408, Val Loss: 1.5457, Val Acc: 0.5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=0.722, acc=0.76] \n",
      "Val Epoch: 19: 100%|██████████| 20/20 [00:01<00:00, 10.43it/s, loss=1.72, acc=0.511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.25, Train Loss: 0.7322, Train Acc: 0.7593, Val Loss: 1.6667, Val Acc: 0.5421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=0.65, acc=0.783] \n",
      "Val Epoch: 20: 100%|██████████| 20/20 [00:01<00:00, 10.50it/s, loss=1.38, acc=0.562] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.23333333333333334, Train Loss: 0.6554, Train Acc: 0.7861, Val Loss: 1.4585, Val Acc: 0.5865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.687, acc=0.775]\n",
      "Val Epoch: 21: 100%|██████████| 20/20 [00:01<00:00, 10.53it/s, loss=1.98, acc=0.415] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.21666666666666667, Train Loss: 0.6081, Train Acc: 0.8000, Val Loss: 1.3913, Val Acc: 0.5888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=0.561, acc=0.803]\n",
      "Val Epoch: 22: 100%|██████████| 20/20 [00:01<00:00, 10.49it/s, loss=1.49, acc=0.511] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.2, Train Loss: 0.5402, Train Acc: 0.8247, Val Loss: 1.5137, Val Acc: 0.5849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.529, acc=0.838]\n",
      "Val Epoch: 23: 100%|██████████| 20/20 [00:01<00:00, 10.46it/s, loss=1.6, acc=0.526]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.18333333333333335, Train Loss: 0.4958, Train Acc: 0.8355, Val Loss: 1.4504, Val Acc: 0.5911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24: 100%|██████████| 33/33 [00:05<00:00,  5.50it/s, loss=0.481, acc=0.832]\n",
      "Val Epoch: 24: 100%|██████████| 20/20 [00:01<00:00, 10.47it/s, loss=1.85, acc=0.493] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.16666666666666669, Train Loss: 0.4244, Train Acc: 0.8606, Val Loss: 1.4523, Val Acc: 0.6080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=0.439, acc=0.834]\n",
      "Val Epoch: 25: 100%|██████████| 20/20 [00:01<00:00, 10.56it/s, loss=1.31, acc=0.603] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.15000000000000002, Train Loss: 0.3672, Train Acc: 0.8783, Val Loss: 1.4505, Val Acc: 0.6119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.289, acc=0.906]\n",
      "Val Epoch: 26: 100%|██████████| 20/20 [00:01<00:00, 10.41it/s, loss=1.77, acc=0.5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.13333333333333336, Train Loss: 0.2894, Train Acc: 0.9048, Val Loss: 1.4177, Val Acc: 0.6269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=0.331, acc=0.879]\n",
      "Val Epoch: 27: 100%|██████████| 20/20 [00:01<00:00, 10.47it/s, loss=1.82, acc=0.522] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.11666666666666664, Train Loss: 0.2475, Train Acc: 0.9197, Val Loss: 1.4623, Val Acc: 0.6312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=0.211, acc=0.932]\n",
      "Val Epoch: 28: 100%|██████████| 20/20 [00:01<00:00, 10.39it/s, loss=1.94, acc=0.5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.09999999999999998, Train Loss: 0.1942, Train Acc: 0.9382, Val Loss: 1.4261, Val Acc: 0.6387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.126, acc=0.961] \n",
      "Val Epoch: 29: 100%|██████████| 20/20 [00:01<00:00, 10.57it/s, loss=2.08, acc=0.507] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.08333333333333331, Train Loss: 0.1416, Train Acc: 0.9551, Val Loss: 1.4992, Val Acc: 0.6378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.118, acc=0.967] \n",
      "Val Epoch: 30: 100%|██████████| 20/20 [00:01<00:00, 10.43it/s, loss=1.15, acc=0.64]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.06666666666666665, Train Loss: 0.0985, Train Acc: 0.9699, Val Loss: 1.3993, Val Acc: 0.6591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=0.0523, acc=0.988]\n",
      "Val Epoch: 31: 100%|██████████| 20/20 [00:01<00:00, 10.55it/s, loss=1.87, acc=0.533] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.04999999999999999, Train Loss: 0.0672, Train Acc: 0.9822, Val Loss: 1.4123, Val Acc: 0.6639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=0.0418, acc=0.986]\n",
      "Val Epoch: 32: 100%|██████████| 20/20 [00:01<00:00, 10.52it/s, loss=1.43, acc=0.618] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.033333333333333326, Train Loss: 0.0491, Train Acc: 0.9891, Val Loss: 1.3843, Val Acc: 0.6721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33: 100%|██████████| 33/33 [00:06<00:00,  5.43it/s, loss=0.0285, acc=0.996]\n",
      "Val Epoch: 33: 100%|██████████| 20/20 [00:01<00:00, 10.52it/s, loss=1.43, acc=0.61]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.016666666666666663, Train Loss: 0.0359, Train Acc: 0.9925, Val Loss: 1.3676, Val Acc: 0.6782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 34: 100%|██████████| 33/33 [00:06<00:00,  5.43it/s, loss=0.0287, acc=0.996]\n",
      "Val Epoch: 34: 100%|██████████| 20/20 [00:01<00:00, 10.46it/s, loss=1.44, acc=0.599] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.0, Train Loss: 0.0296, Train Acc: 0.9946, Val Loss: 1.3643, Val Acc: 0.6787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.09it/s]\n",
      "Train Epoch: 0: 100%|██████████| 33/33 [00:05<00:00,  5.51it/s, loss=2.57, acc=0.16]  \n",
      "Val Epoch: 0: 100%|██████████| 20/20 [00:01<00:00, 10.41it/s, loss=22.8, acc=0.00368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.1, Train Loss: 2.7833, Train Acc: 0.1590, Val Loss: 25.7440, Val Acc: 0.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=2.42, acc=0.242]\n",
      "Val Epoch: 1: 100%|██████████| 20/20 [00:01<00:00, 10.42it/s, loss=3.22, acc=0.136] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.2, Train Loss: 2.4933, Train Acc: 0.2373, Val Loss: 3.0767, Val Acc: 0.2070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=2.24, acc=0.324]\n",
      "Val Epoch: 2: 100%|██████████| 20/20 [00:01<00:00, 10.57it/s, loss=3.6, acc=0.0294] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3, Train Loss: 2.2807, Train Acc: 0.2946, Val Loss: 2.4293, Val Acc: 0.2650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3: 100%|██████████| 33/33 [00:05<00:00,  5.51it/s, loss=2.13, acc=0.33] \n",
      "Val Epoch: 3: 100%|██████████| 20/20 [00:01<00:00, 10.44it/s, loss=2.2, acc=0.272]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4, Train Loss: 2.1866, Train Acc: 0.3262, Val Loss: 2.4035, Val Acc: 0.2788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=2.1, acc=0.332] \n",
      "Val Epoch: 4: 100%|██████████| 20/20 [00:01<00:00, 10.47it/s, loss=2.09, acc=0.324] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.5, Train Loss: 2.0914, Train Acc: 0.3537, Val Loss: 2.1748, Val Acc: 0.3352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=2, acc=0.395]   \n",
      "Val Epoch: 5: 100%|██████████| 20/20 [00:01<00:00, 10.55it/s, loss=2.44, acc=0.228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.48333333333333334, Train Loss: 1.9593, Train Acc: 0.3891, Val Loss: 2.1889, Val Acc: 0.3237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=1.76, acc=0.432]\n",
      "Val Epoch: 6: 100%|██████████| 20/20 [00:01<00:00, 10.44it/s, loss=1.96, acc=0.36]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4666666666666667, Train Loss: 1.8388, Train Acc: 0.4277, Val Loss: 2.0985, Val Acc: 0.3491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=1.79, acc=0.438]\n",
      "Val Epoch: 7: 100%|██████████| 20/20 [00:01<00:00, 10.50it/s, loss=2.28, acc=0.294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.45, Train Loss: 1.7313, Train Acc: 0.4597, Val Loss: 1.9831, Val Acc: 0.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=1.55, acc=0.523]\n",
      "Val Epoch: 8: 100%|██████████| 20/20 [00:01<00:00, 10.50it/s, loss=2.4, acc=0.316] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.43333333333333335, Train Loss: 1.6312, Train Acc: 0.4840, Val Loss: 2.0417, Val Acc: 0.3718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=1.5, acc=0.512] \n",
      "Val Epoch: 9: 100%|██████████| 20/20 [00:01<00:00, 10.45it/s, loss=2.91, acc=0.25] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4166666666666667, Train Loss: 1.5326, Train Acc: 0.5133, Val Loss: 1.9244, Val Acc: 0.4241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=1.39, acc=0.537]\n",
      "Val Epoch: 10: 100%|██████████| 20/20 [00:01<00:00, 10.45it/s, loss=1.54, acc=0.482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4, Train Loss: 1.4429, Train Acc: 0.5444, Val Loss: 1.6573, Val Acc: 0.4851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=1.2, acc=0.602] \n",
      "Val Epoch: 11: 100%|██████████| 20/20 [00:01<00:00, 10.51it/s, loss=2.34, acc=0.309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3833333333333333, Train Loss: 1.3362, Train Acc: 0.5778, Val Loss: 1.7286, Val Acc: 0.4759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=1.28, acc=0.604]\n",
      "Val Epoch: 12: 100%|██████████| 20/20 [00:02<00:00,  9.22it/s, loss=1.94, acc=0.441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3666666666666667, Train Loss: 1.2546, Train Acc: 0.5987, Val Loss: 1.6743, Val Acc: 0.4858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13: 100%|██████████| 33/33 [00:05<00:00,  5.51it/s, loss=1.15, acc=0.639]\n",
      "Val Epoch: 13: 100%|██████████| 20/20 [00:01<00:00, 10.60it/s, loss=1.92, acc=0.386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.35, Train Loss: 1.1648, Train Acc: 0.6294, Val Loss: 1.6653, Val Acc: 0.4845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14: 100%|██████████| 33/33 [00:06<00:00,  5.50it/s, loss=1.09, acc=0.641] \n",
      "Val Epoch: 14: 100%|██████████| 20/20 [00:01<00:00, 10.48it/s, loss=1.73, acc=0.438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.33333333333333337, Train Loss: 1.1028, Train Acc: 0.6487, Val Loss: 1.6913, Val Acc: 0.4922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=0.978, acc=0.697]\n",
      "Val Epoch: 15: 100%|██████████| 20/20 [00:01<00:00, 10.50it/s, loss=1.38, acc=0.57] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.31666666666666665, Train Loss: 1.0051, Train Acc: 0.6753, Val Loss: 1.5577, Val Acc: 0.5379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=1.1, acc=0.658]  \n",
      "Val Epoch: 16: 100%|██████████| 20/20 [00:01<00:00, 10.47it/s, loss=1.54, acc=0.562] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3, Train Loss: 0.9398, Train Acc: 0.6958, Val Loss: 1.8211, Val Acc: 0.4948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=0.941, acc=0.695]\n",
      "Val Epoch: 17: 100%|██████████| 20/20 [00:01<00:00, 10.64it/s, loss=2.17, acc=0.368] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.2833333333333333, Train Loss: 0.8635, Train Acc: 0.7212, Val Loss: 1.5932, Val Acc: 0.5304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=0.855, acc=0.719]\n",
      "Val Epoch: 18: 100%|██████████| 20/20 [00:01<00:00, 10.54it/s, loss=1.59, acc=0.529] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.26666666666666666, Train Loss: 0.8057, Train Acc: 0.7360, Val Loss: 1.5315, Val Acc: 0.5564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=0.784, acc=0.713]\n",
      "Val Epoch: 19: 100%|██████████| 20/20 [00:01<00:00, 10.51it/s, loss=1.85, acc=0.467] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.25, Train Loss: 0.7555, Train Acc: 0.7520, Val Loss: 1.4757, Val Acc: 0.5677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20: 100%|██████████| 33/33 [00:05<00:00,  5.50it/s, loss=0.664, acc=0.779]\n",
      "Val Epoch: 20: 100%|██████████| 20/20 [00:01<00:00, 10.41it/s, loss=1.4, acc=0.574] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.23333333333333334, Train Loss: 0.6881, Train Acc: 0.7732, Val Loss: 1.5614, Val Acc: 0.5575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=0.628, acc=0.801]\n",
      "Val Epoch: 21: 100%|██████████| 20/20 [00:01<00:00, 10.53it/s, loss=1.24, acc=0.57]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.21666666666666667, Train Loss: 0.6134, Train Acc: 0.8024, Val Loss: 1.4495, Val Acc: 0.5829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22: 100%|██████████| 33/33 [00:05<00:00,  5.52it/s, loss=0.52, acc=0.832] \n",
      "Val Epoch: 22: 100%|██████████| 20/20 [00:01<00:00, 10.53it/s, loss=2.34, acc=0.404] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.2, Train Loss: 0.5589, Train Acc: 0.8188, Val Loss: 1.3988, Val Acc: 0.5997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.565, acc=0.82] \n",
      "Val Epoch: 23: 100%|██████████| 20/20 [00:01<00:00, 10.54it/s, loss=2.06, acc=0.426] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.18333333333333335, Train Loss: 0.5092, Train Acc: 0.8337, Val Loss: 1.4959, Val Acc: 0.5906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=0.498, acc=0.824]\n",
      "Val Epoch: 24: 100%|██████████| 20/20 [00:01<00:00, 10.43it/s, loss=2.68, acc=0.404] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.16666666666666669, Train Loss: 0.4439, Train Acc: 0.8542, Val Loss: 1.6349, Val Acc: 0.5694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.375, acc=0.875]\n",
      "Val Epoch: 25: 100%|██████████| 20/20 [00:01<00:00, 10.46it/s, loss=2.17, acc=0.419] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.15000000000000002, Train Loss: 0.3684, Train Acc: 0.8795, Val Loss: 1.4485, Val Acc: 0.6119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.337, acc=0.879]\n",
      "Val Epoch: 26: 100%|██████████| 20/20 [00:01<00:00, 10.49it/s, loss=1.94, acc=0.522] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.13333333333333336, Train Loss: 0.3139, Train Acc: 0.8959, Val Loss: 1.4687, Val Acc: 0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27: 100%|██████████| 33/33 [00:06<00:00,  5.44it/s, loss=0.29, acc=0.9]   \n",
      "Val Epoch: 27: 100%|██████████| 20/20 [00:01<00:00, 10.43it/s, loss=1.92, acc=0.518] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.11666666666666664, Train Loss: 0.2720, Train Acc: 0.9113, Val Loss: 1.3527, Val Acc: 0.6378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=0.222, acc=0.924]\n",
      "Val Epoch: 28: 100%|██████████| 20/20 [00:01<00:00, 10.60it/s, loss=1.38, acc=0.632] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.09999999999999998, Train Loss: 0.2076, Train Acc: 0.9330, Val Loss: 1.3516, Val Acc: 0.6467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=0.16, acc=0.949] \n",
      "Val Epoch: 29: 100%|██████████| 20/20 [00:01<00:00, 10.43it/s, loss=1.99, acc=0.511] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.08333333333333331, Train Loss: 0.1560, Train Acc: 0.9509, Val Loss: 1.3543, Val Acc: 0.6537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30: 100%|██████████| 33/33 [00:05<00:00,  5.50it/s, loss=0.0933, acc=0.977]\n",
      "Val Epoch: 30: 100%|██████████| 20/20 [00:01<00:00, 10.44it/s, loss=1.99, acc=0.526] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.06666666666666665, Train Loss: 0.1117, Train Acc: 0.9674, Val Loss: 1.3677, Val Acc: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.0666, acc=0.98] \n",
      "Val Epoch: 31: 100%|██████████| 20/20 [00:01<00:00, 10.49it/s, loss=1.77, acc=0.562] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.04999999999999999, Train Loss: 0.0737, Train Acc: 0.9801, Val Loss: 1.3599, Val Acc: 0.6627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=0.0596, acc=0.98] \n",
      "Val Epoch: 32: 100%|██████████| 20/20 [00:01<00:00, 10.48it/s, loss=1.63, acc=0.607] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.033333333333333326, Train Loss: 0.0550, Train Acc: 0.9865, Val Loss: 1.3365, Val Acc: 0.6745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33: 100%|██████████| 33/33 [00:06<00:00,  5.50it/s, loss=0.0479, acc=0.988]\n",
      "Val Epoch: 33: 100%|██████████| 20/20 [00:01<00:00, 10.60it/s, loss=1.54, acc=0.614] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.016666666666666663, Train Loss: 0.0388, Train Acc: 0.9916, Val Loss: 1.3110, Val Acc: 0.6796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 34: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.0432, acc=0.982]\n",
      "Val Epoch: 34: 100%|██████████| 20/20 [00:01<00:00, 10.46it/s, loss=1.56, acc=0.603] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.0, Train Loss: 0.0319, Train Acc: 0.9947, Val Loss: 1.3054, Val Acc: 0.6804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.12it/s]\n",
      "Train Epoch: 0: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=2.65, acc=0.195]\n",
      "Val Epoch: 0: 100%|██████████| 20/20 [00:01<00:00, 10.56it/s, loss=1.71, acc=0.507]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.1, Train Loss: 2.7938, Train Acc: 0.1524, Val Loss: 5.4948, Val Acc: 0.1254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=2.4, acc=0.262] \n",
      "Val Epoch: 1: 100%|██████████| 20/20 [00:01<00:00, 10.42it/s, loss=2.95, acc=0.0294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.2, Train Loss: 2.5322, Train Acc: 0.2270, Val Loss: 2.6103, Val Acc: 0.2072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=2.4, acc=0.242] \n",
      "Val Epoch: 2: 100%|██████████| 20/20 [00:01<00:00, 10.51it/s, loss=2.61, acc=0.129] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3, Train Loss: 2.3875, Train Acc: 0.2643, Val Loss: 2.5784, Val Acc: 0.2382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3: 100%|██████████| 33/33 [00:06<00:00,  5.43it/s, loss=2.21, acc=0.338]\n",
      "Val Epoch: 3: 100%|██████████| 20/20 [00:01<00:00, 10.43it/s, loss=2.88, acc=0.0699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4, Train Loss: 2.2214, Train Acc: 0.3127, Val Loss: 2.5360, Val Acc: 0.2469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=2.04, acc=0.379]\n",
      "Val Epoch: 4: 100%|██████████| 20/20 [00:01<00:00, 10.33it/s, loss=2.89, acc=0.136] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.5, Train Loss: 2.1178, Train Acc: 0.3447, Val Loss: 2.2345, Val Acc: 0.3196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=1.93, acc=0.408]\n",
      "Val Epoch: 5: 100%|██████████| 20/20 [00:01<00:00, 10.60it/s, loss=2.69, acc=0.158] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.48333333333333334, Train Loss: 2.0120, Train Acc: 0.3784, Val Loss: 2.1555, Val Acc: 0.3269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=1.98, acc=0.391]\n",
      "Val Epoch: 6: 100%|██████████| 20/20 [00:01<00:00, 10.52it/s, loss=1.92, acc=0.412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4666666666666667, Train Loss: 1.8926, Train Acc: 0.4113, Val Loss: 2.1093, Val Acc: 0.3498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=1.77, acc=0.449]\n",
      "Val Epoch: 7: 100%|██████████| 20/20 [00:01<00:00, 10.49it/s, loss=2.58, acc=0.176] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.45, Train Loss: 1.7868, Train Acc: 0.4378, Val Loss: 2.0517, Val Acc: 0.3664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8: 100%|██████████| 33/33 [00:06<00:00,  5.44it/s, loss=1.66, acc=0.5]  \n",
      "Val Epoch: 8: 100%|██████████| 20/20 [00:01<00:00, 10.49it/s, loss=1.69, acc=0.478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.43333333333333335, Train Loss: 1.6721, Train Acc: 0.4735, Val Loss: 1.9486, Val Acc: 0.4004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=1.53, acc=0.525]\n",
      "Val Epoch: 9: 100%|██████████| 20/20 [00:01<00:00, 10.46it/s, loss=2.23, acc=0.327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4166666666666667, Train Loss: 1.5780, Train Acc: 0.4992, Val Loss: 1.8080, Val Acc: 0.4299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=1.45, acc=0.541]\n",
      "Val Epoch: 10: 100%|██████████| 20/20 [00:01<00:00, 10.39it/s, loss=1.78, acc=0.463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4, Train Loss: 1.5004, Train Acc: 0.5228, Val Loss: 1.9810, Val Acc: 0.4046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=1.38, acc=0.588]\n",
      "Val Epoch: 11: 100%|██████████| 20/20 [00:01<00:00, 10.54it/s, loss=2.09, acc=0.346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3833333333333333, Train Loss: 1.3653, Train Acc: 0.5634, Val Loss: 1.9488, Val Acc: 0.4292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12: 100%|██████████| 33/33 [00:06<00:00,  5.43it/s, loss=1.27, acc=0.578]\n",
      "Val Epoch: 12: 100%|██████████| 20/20 [00:01<00:00, 10.44it/s, loss=2.76, acc=0.228] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3666666666666667, Train Loss: 1.2760, Train Acc: 0.5923, Val Loss: 1.7771, Val Acc: 0.4586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13: 100%|██████████| 33/33 [00:06<00:00,  5.44it/s, loss=1.22, acc=0.613]\n",
      "Val Epoch: 13: 100%|██████████| 20/20 [00:01<00:00, 10.44it/s, loss=1.48, acc=0.54] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.35, Train Loss: 1.1820, Train Acc: 0.6233, Val Loss: 1.6363, Val Acc: 0.4895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=1.08, acc=0.627] \n",
      "Val Epoch: 14: 100%|██████████| 20/20 [00:01<00:00, 10.43it/s, loss=0.896, acc=0.691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.33333333333333337, Train Loss: 1.1018, Train Acc: 0.6459, Val Loss: 2.0340, Val Acc: 0.4254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=1.07, acc=0.639] \n",
      "Val Epoch: 15: 100%|██████████| 20/20 [00:01<00:00, 10.41it/s, loss=2.03, acc=0.386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.31666666666666665, Train Loss: 1.0316, Train Acc: 0.6663, Val Loss: 1.6269, Val Acc: 0.5199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=0.972, acc=0.678]\n",
      "Val Epoch: 16: 100%|██████████| 20/20 [00:01<00:00, 10.55it/s, loss=1.67, acc=0.496] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3, Train Loss: 0.9488, Train Acc: 0.6911, Val Loss: 1.6596, Val Acc: 0.5022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=1.07, acc=0.682] \n",
      "Val Epoch: 17: 100%|██████████| 20/20 [00:01<00:00, 10.54it/s, loss=1.35, acc=0.588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.2833333333333333, Train Loss: 0.8944, Train Acc: 0.7116, Val Loss: 1.6758, Val Acc: 0.5235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=0.845, acc=0.732]\n",
      "Val Epoch: 18: 100%|██████████| 20/20 [00:01<00:00, 10.44it/s, loss=2, acc=0.375]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.26666666666666666, Train Loss: 0.8292, Train Acc: 0.7317, Val Loss: 1.5400, Val Acc: 0.5456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19: 100%|██████████| 33/33 [00:06<00:00,  5.44it/s, loss=0.832, acc=0.738]\n",
      "Val Epoch: 19: 100%|██████████| 20/20 [00:01<00:00, 10.45it/s, loss=2.23, acc=0.426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.25, Train Loss: 0.7665, Train Acc: 0.7508, Val Loss: 1.8361, Val Acc: 0.5083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=0.737, acc=0.793]\n",
      "Val Epoch: 20: 100%|██████████| 20/20 [00:01<00:00, 10.47it/s, loss=1.71, acc=0.471] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.23333333333333334, Train Loss: 0.6923, Train Acc: 0.7757, Val Loss: 1.4925, Val Acc: 0.5705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=0.712, acc=0.773]\n",
      "Val Epoch: 21: 100%|██████████| 20/20 [00:02<00:00,  9.17it/s, loss=1.9, acc=0.452]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.21666666666666667, Train Loss: 0.6336, Train Acc: 0.7913, Val Loss: 1.5472, Val Acc: 0.5643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=0.642, acc=0.793]\n",
      "Val Epoch: 22: 100%|██████████| 20/20 [00:01<00:00, 10.54it/s, loss=1.93, acc=0.482] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.2, Train Loss: 0.5640, Train Acc: 0.8163, Val Loss: 1.4764, Val Acc: 0.5949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=0.605, acc=0.811]\n",
      "Val Epoch: 23: 100%|██████████| 20/20 [00:01<00:00, 10.38it/s, loss=1.2, acc=0.614] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.18333333333333335, Train Loss: 0.5162, Train Acc: 0.8306, Val Loss: 1.6170, Val Acc: 0.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=0.45, acc=0.844] \n",
      "Val Epoch: 24: 100%|██████████| 20/20 [00:01<00:00, 10.49it/s, loss=1.59, acc=0.504] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.16666666666666669, Train Loss: 0.4611, Train Acc: 0.8500, Val Loss: 1.5358, Val Acc: 0.5949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.426, acc=0.855]\n",
      "Val Epoch: 25: 100%|██████████| 20/20 [00:01<00:00, 10.47it/s, loss=1.69, acc=0.515] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.15000000000000002, Train Loss: 0.3901, Train Acc: 0.8703, Val Loss: 1.4493, Val Acc: 0.6140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=0.379, acc=0.875]\n",
      "Val Epoch: 26: 100%|██████████| 20/20 [00:01<00:00, 10.58it/s, loss=1.33, acc=0.603] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.13333333333333336, Train Loss: 0.3221, Train Acc: 0.8945, Val Loss: 1.3594, Val Acc: 0.6382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=0.34, acc=0.889] \n",
      "Val Epoch: 27: 100%|██████████| 20/20 [00:01<00:00, 10.53it/s, loss=1.57, acc=0.577] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.11666666666666664, Train Loss: 0.2659, Train Acc: 0.9159, Val Loss: 1.4906, Val Acc: 0.6225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=0.206, acc=0.934]\n",
      "Val Epoch: 28: 100%|██████████| 20/20 [00:01<00:00, 10.51it/s, loss=1.34, acc=0.654] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.09999999999999998, Train Loss: 0.2102, Train Acc: 0.9334, Val Loss: 1.5445, Val Acc: 0.6151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=0.191, acc=0.941]\n",
      "Val Epoch: 29: 100%|██████████| 20/20 [00:01<00:00, 10.34it/s, loss=1.85, acc=0.526] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.08333333333333331, Train Loss: 0.1563, Train Acc: 0.9529, Val Loss: 1.4684, Val Acc: 0.6387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=0.106, acc=0.965] \n",
      "Val Epoch: 30: 100%|██████████| 20/20 [00:01<00:00, 10.53it/s, loss=1.9, acc=0.555]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.06666666666666665, Train Loss: 0.1155, Train Acc: 0.9647, Val Loss: 1.4355, Val Acc: 0.6536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31: 100%|██████████| 33/33 [00:05<00:00,  5.50it/s, loss=0.0829, acc=0.975]\n",
      "Val Epoch: 31: 100%|██████████| 20/20 [00:01<00:00, 10.55it/s, loss=1.48, acc=0.596] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.04999999999999999, Train Loss: 0.0848, Train Acc: 0.9738, Val Loss: 1.4285, Val Acc: 0.6633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.0386, acc=0.998]\n",
      "Val Epoch: 32: 100%|██████████| 20/20 [00:01<00:00, 10.46it/s, loss=1.6, acc=0.596]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.033333333333333326, Train Loss: 0.0582, Train Acc: 0.9859, Val Loss: 1.3695, Val Acc: 0.6719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33: 100%|██████████| 33/33 [00:05<00:00,  5.51it/s, loss=0.0394, acc=0.99] \n",
      "Val Epoch: 33: 100%|██████████| 20/20 [00:01<00:00, 10.63it/s, loss=1.38, acc=0.636] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.016666666666666663, Train Loss: 0.0408, Train Acc: 0.9908, Val Loss: 1.3625, Val Acc: 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 34: 100%|██████████| 33/33 [00:05<00:00,  5.50it/s, loss=0.0334, acc=0.998]\n",
      "Val Epoch: 34: 100%|██████████| 20/20 [00:01<00:00, 10.58it/s, loss=1.52, acc=0.603] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.0, Train Loss: 0.0312, Train Acc: 0.9950, Val Loss: 1.3580, Val Acc: 0.6781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.19it/s]\n",
      "Train Epoch: 0: 100%|██████████| 33/33 [00:05<00:00,  5.51it/s, loss=2.51, acc=0.248]\n",
      "Val Epoch: 0: 100%|██████████| 20/20 [00:01<00:00, 10.66it/s, loss=12.6, acc=0]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.1, Train Loss: 2.8066, Train Acc: 0.1549, Val Loss: 13.7727, Val Acc: 0.0679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1: 100%|██████████| 33/33 [00:05<00:00,  5.52it/s, loss=2.47, acc=0.264]\n",
      "Val Epoch: 1: 100%|██████████| 20/20 [00:01<00:00, 10.45it/s, loss=2.63, acc=0.0993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.2, Train Loss: 2.4714, Train Acc: 0.2394, Val Loss: 2.7451, Val Acc: 0.2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=2.16, acc=0.334]\n",
      "Val Epoch: 2: 100%|██████████| 20/20 [00:01<00:00, 10.52it/s, loss=3.91, acc=0.00735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3, Train Loss: 2.3233, Train Acc: 0.2815, Val Loss: 2.8127, Val Acc: 0.2255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3: 100%|██████████| 33/33 [00:05<00:00,  5.51it/s, loss=2.17, acc=0.307]\n",
      "Val Epoch: 3: 100%|██████████| 20/20 [00:01<00:00, 10.56it/s, loss=3.75, acc=0.011] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4, Train Loss: 2.2001, Train Acc: 0.3166, Val Loss: 2.3313, Val Acc: 0.2919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4: 100%|██████████| 33/33 [00:05<00:00,  5.52it/s, loss=2.1, acc=0.332] \n",
      "Val Epoch: 4: 100%|██████████| 20/20 [00:01<00:00, 10.57it/s, loss=2.75, acc=0.0735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.5, Train Loss: 2.1199, Train Acc: 0.3398, Val Loss: 2.3671, Val Acc: 0.2859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5: 100%|██████████| 33/33 [00:06<00:00,  5.44it/s, loss=1.8, acc=0.451] \n",
      "Val Epoch: 5: 100%|██████████| 20/20 [00:01<00:00, 10.55it/s, loss=2.66, acc=0.11]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.48333333333333334, Train Loss: 1.9647, Train Acc: 0.3910, Val Loss: 2.0964, Val Acc: 0.3578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6: 100%|██████████| 33/33 [00:05<00:00,  5.50it/s, loss=1.71, acc=0.461]\n",
      "Val Epoch: 6: 100%|██████████| 20/20 [00:01<00:00, 10.50it/s, loss=2.72, acc=0.132] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4666666666666667, Train Loss: 1.8422, Train Acc: 0.4251, Val Loss: 2.0855, Val Acc: 0.3588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7: 100%|██████████| 33/33 [00:05<00:00,  5.50it/s, loss=1.78, acc=0.447]\n",
      "Val Epoch: 7: 100%|██████████| 20/20 [00:01<00:00, 10.67it/s, loss=2.77, acc=0.162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.45, Train Loss: 1.7514, Train Acc: 0.4482, Val Loss: 2.0261, Val Acc: 0.3753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8: 100%|██████████| 33/33 [00:05<00:00,  5.50it/s, loss=1.65, acc=0.473]\n",
      "Val Epoch: 8: 100%|██████████| 20/20 [00:01<00:00, 10.51it/s, loss=1.84, acc=0.349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.43333333333333335, Train Loss: 1.6232, Train Acc: 0.4889, Val Loss: 1.9534, Val Acc: 0.3998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9: 100%|██████████| 33/33 [00:05<00:00,  5.52it/s, loss=1.51, acc=0.527]\n",
      "Val Epoch: 9: 100%|██████████| 20/20 [00:01<00:00, 10.60it/s, loss=3.07, acc=0.235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4166666666666667, Train Loss: 1.5478, Train Acc: 0.5149, Val Loss: 2.0802, Val Acc: 0.3875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10: 100%|██████████| 33/33 [00:05<00:00,  5.50it/s, loss=1.44, acc=0.551]\n",
      "Val Epoch: 10: 100%|██████████| 20/20 [00:01<00:00, 10.61it/s, loss=1.8, acc=0.404] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.4, Train Loss: 1.4390, Train Acc: 0.5405, Val Loss: 2.0078, Val Acc: 0.4063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11: 100%|██████████| 33/33 [00:05<00:00,  5.50it/s, loss=1.34, acc=0.58] \n",
      "Val Epoch: 11: 100%|██████████| 20/20 [00:01<00:00, 10.51it/s, loss=2.18, acc=0.335] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3833333333333333, Train Loss: 1.3385, Train Acc: 0.5737, Val Loss: 2.0394, Val Acc: 0.4024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=1.22, acc=0.598]\n",
      "Val Epoch: 12: 100%|██████████| 20/20 [00:01<00:00, 10.57it/s, loss=2.15, acc=0.382] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3666666666666667, Train Loss: 1.2535, Train Acc: 0.5960, Val Loss: 1.8233, Val Acc: 0.4522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=1.28, acc=0.596]\n",
      "Val Epoch: 13: 100%|██████████| 20/20 [00:01<00:00, 10.45it/s, loss=1.6, acc=0.5]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.35, Train Loss: 1.1681, Train Acc: 0.6255, Val Loss: 1.5753, Val Acc: 0.5115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=1.06, acc=0.65]  \n",
      "Val Epoch: 14: 100%|██████████| 20/20 [00:01<00:00, 10.45it/s, loss=1.95, acc=0.397] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.33333333333333337, Train Loss: 1.0878, Train Acc: 0.6491, Val Loss: 1.6556, Val Acc: 0.5041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=1.02, acc=0.67]  \n",
      "Val Epoch: 15: 100%|██████████| 20/20 [00:01<00:00, 10.56it/s, loss=1.36, acc=0.559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.31666666666666665, Train Loss: 1.0011, Train Acc: 0.6788, Val Loss: 1.4970, Val Acc: 0.5392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.975, acc=0.682]\n",
      "Val Epoch: 16: 100%|██████████| 20/20 [00:01<00:00, 10.49it/s, loss=1.61, acc=0.522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.3, Train Loss: 0.9426, Train Acc: 0.6942, Val Loss: 1.6177, Val Acc: 0.5323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=0.825, acc=0.732]\n",
      "Val Epoch: 17: 100%|██████████| 20/20 [00:01<00:00, 10.49it/s, loss=1.5, acc=0.537]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.2833333333333333, Train Loss: 0.8835, Train Acc: 0.7133, Val Loss: 1.7086, Val Acc: 0.5222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.779, acc=0.764]\n",
      "Val Epoch: 18: 100%|██████████| 20/20 [00:01<00:00, 10.48it/s, loss=1.49, acc=0.507] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.26666666666666666, Train Loss: 0.7992, Train Acc: 0.7421, Val Loss: 1.4220, Val Acc: 0.5614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=0.824, acc=0.725]\n",
      "Val Epoch: 19: 100%|██████████| 20/20 [00:01<00:00, 10.47it/s, loss=1.98, acc=0.46] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.25, Train Loss: 0.7461, Train Acc: 0.7550, Val Loss: 1.9330, Val Acc: 0.5009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.723, acc=0.775]\n",
      "Val Epoch: 20: 100%|██████████| 20/20 [00:01<00:00, 10.52it/s, loss=1.16, acc=0.632] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.23333333333333334, Train Loss: 0.6845, Train Acc: 0.7766, Val Loss: 1.4697, Val Acc: 0.5681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 21: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.623, acc=0.789]\n",
      "Val Epoch: 21: 100%|██████████| 20/20 [00:01<00:00, 10.45it/s, loss=1.74, acc=0.485] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.21666666666666667, Train Loss: 0.6114, Train Acc: 0.7998, Val Loss: 1.6453, Val Acc: 0.5439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=0.575, acc=0.82] \n",
      "Val Epoch: 22: 100%|██████████| 20/20 [00:01<00:00, 10.37it/s, loss=2.31, acc=0.375] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.2, Train Loss: 0.5647, Train Acc: 0.8162, Val Loss: 1.4351, Val Acc: 0.5994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23: 100%|██████████| 33/33 [00:06<00:00,  5.42it/s, loss=0.468, acc=0.855]\n",
      "Val Epoch: 23: 100%|██████████| 20/20 [00:01<00:00, 10.48it/s, loss=2.29, acc=0.426] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.18333333333333335, Train Loss: 0.4955, Train Acc: 0.8412, Val Loss: 1.5246, Val Acc: 0.5831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 24: 100%|██████████| 33/33 [00:06<00:00,  5.46it/s, loss=0.46, acc=0.848] \n",
      "Val Epoch: 24: 100%|██████████| 20/20 [00:01<00:00, 10.37it/s, loss=1.34, acc=0.603] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.16666666666666669, Train Loss: 0.4176, Train Acc: 0.8615, Val Loss: 1.4814, Val Acc: 0.5992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25: 100%|██████████| 33/33 [00:06<00:00,  5.45it/s, loss=0.456, acc=0.846]\n",
      "Val Epoch: 25: 100%|██████████| 20/20 [00:01<00:00, 10.57it/s, loss=1.67, acc=0.537] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.15000000000000002, Train Loss: 0.3714, Train Acc: 0.8768, Val Loss: 1.3973, Val Acc: 0.6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 26: 100%|██████████| 33/33 [00:06<00:00,  5.47it/s, loss=0.321, acc=0.887]\n",
      "Val Epoch: 26: 100%|██████████| 20/20 [00:01<00:00, 10.38it/s, loss=1.99, acc=0.515] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.13333333333333336, Train Loss: 0.3046, Train Acc: 0.9001, Val Loss: 1.4145, Val Acc: 0.6253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=0.202, acc=0.945]\n",
      "Val Epoch: 27: 100%|██████████| 20/20 [00:01<00:00, 10.44it/s, loss=1.84, acc=0.507] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.11666666666666664, Train Loss: 0.2494, Train Acc: 0.9202, Val Loss: 1.4879, Val Acc: 0.6187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=0.221, acc=0.924]\n",
      "Val Epoch: 28: 100%|██████████| 20/20 [00:01<00:00, 10.52it/s, loss=1.62, acc=0.559] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.09999999999999998, Train Loss: 0.1974, Train Acc: 0.9370, Val Loss: 1.4835, Val Acc: 0.6299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29: 100%|██████████| 33/33 [00:06<00:00,  5.48it/s, loss=0.163, acc=0.953]\n",
      "Val Epoch: 29: 100%|██████████| 20/20 [00:01<00:00, 10.51it/s, loss=0.983, acc=0.706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.08333333333333331, Train Loss: 0.1449, Train Acc: 0.9548, Val Loss: 1.4739, Val Acc: 0.6328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 30: 100%|██████████| 33/33 [00:06<00:00,  5.21it/s, loss=0.0934, acc=0.975]\n",
      "Val Epoch: 30: 100%|██████████| 20/20 [00:01<00:00, 10.44it/s, loss=1.42, acc=0.632] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.06666666666666665, Train Loss: 0.1034, Train Acc: 0.9696, Val Loss: 1.3756, Val Acc: 0.6587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 31: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=0.0934, acc=0.973]\n",
      "Val Epoch: 31: 100%|██████████| 20/20 [00:01<00:00, 10.46it/s, loss=1.45, acc=0.603] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.04999999999999999, Train Loss: 0.0649, Train Acc: 0.9836, Val Loss: 1.3562, Val Acc: 0.6666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32: 100%|██████████| 33/33 [00:06<00:00,  5.44it/s, loss=0.0505, acc=0.982]\n",
      "Val Epoch: 32: 100%|██████████| 20/20 [00:01<00:00, 10.59it/s, loss=1.7, acc=0.581]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.033333333333333326, Train Loss: 0.0471, Train Acc: 0.9889, Val Loss: 1.3905, Val Acc: 0.6687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=0.0416, acc=0.994]\n",
      "Val Epoch: 33: 100%|██████████| 20/20 [00:01<00:00, 10.41it/s, loss=1.54, acc=0.588] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.016666666666666663, Train Loss: 0.0368, Train Acc: 0.9921, Val Loss: 1.3699, Val Acc: 0.6711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 34: 100%|██████████| 33/33 [00:06<00:00,  5.49it/s, loss=0.0206, acc=0.998]\n",
      "Val Epoch: 34: 100%|██████████| 20/20 [00:01<00:00, 10.42it/s, loss=1.5, acc=0.614]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.0, Train Loss: 0.0289, Train Acc: 0.9946, Val Loss: 1.3611, Val Acc: 0.6751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# See relative accuracies\n",
    "flip_interventions = {}\n",
    "for intensity in [0, 0.1, 0.2, 0.3]:\n",
    "    base_synth_dataset = DiffDataset(path_dict, flip_name='flip', intensity=intensity, num_imgs_per_class=100,\n",
    "                                     transform=resize_train_transform, include_classes=[0])\n",
    "    synth_train_set = torch.utils.data.ConcatDataset([train_ds, base_synth_dataset])\n",
    "    synth_train_loader = torch.utils.data.DataLoader(synth_train_set, batch_size=bsz, shuffle=True, drop_last=True)\n",
    "    flip_interventions[intensity] = [\n",
    "        run_model(synth_train_loader, val_loader, test_loader, set_device=True)\n",
    "        for _ in range (1)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d10f174b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 54.01it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 54.83it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 56.35it/s]\n",
      "100%|██████████| 300/300 [00:05<00:00, 57.32it/s]\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "100%|██████████| 10/10 [00:00<00:00, 66.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consistent with old results 1.0\n",
      "excluding malamute\n",
      "excluding flat-coated retriever\n",
      "excluding curly-coated retriever\n",
      "excluding sennenhunde\n",
      "excluding weimaraner\n",
      "excluding german short-haired pointer\n",
      "excluding belgian sheepdog\n",
      "excluding smooth-haired fox terrier\n",
      "excluding blenheim spaniel\n",
      "excluding ibizan hound\n",
      "excluding shih-tzu\n",
      "excluding coondog\n",
      "excluding liver-spotted dalmatian\n",
      "excluding seizure-alert dog\n",
      "excluding bedlington terrier\n",
      "excluding lapdog\n",
      "excluding brabancon griffon\n",
      "excluding rottweiler\n",
      "excluding wire-haired fox terrier\n",
      "excluding plott hound\n",
      "excluding staffordshire bullterrier\n",
      "excluding staffordshire bullterrier\n",
      "excluding entlebucher\n",
      "excluding housedog\n",
      "excluding appenzeller\n",
      "excluding dandie dinmont\n",
      "excluding vizsla\n",
      "excluding soft-coated wheaten terrier\n",
      "excluding clumber\n",
      "excluding doberman\n",
      "excluding old english sheepdog\n",
      "excluding coonhound\n",
      "excluding black-and-tan coonhound\n",
      "excluding black-and-tan coonhound\n",
      "excluding shetland sheepdog\n",
      "excluding rhodesian ridgeback\n",
      "excluding norwich terrier\n",
      "excluding pekinese\n",
      "excluding great pyrenees\n",
      "excluding leonberg\n",
      "excluding american staffordshire terrier\n",
      "excluding bouvier des flandres\n",
      "excluding bouvier des flandres\n",
      "excluding bouvier des flandres\n",
      "excluding bluetick\n",
      "excluding bullterrier\n",
      "excluding new zealand wren\n",
      "excluding aegypiidae\n",
      "excluding wilson's phalarope\n",
      "excluding adelie\n",
      "excluding protoavis\n",
      "excluding roadrunner\n",
      "excluding blackburn\n",
      "excluding long-billed marsh wren\n",
      "excluding red-shafted flicker\n",
      "excluding dark-eyed junco\n",
      "excluding yellow-crowned night heron\n",
      "excluding eastern meadowlark\n",
      "excluding red-breasted sapsucker\n",
      "excluding clay-colored robin\n",
      "excluding western meadowlark\n",
      "excluding ibero-mesornis\n",
      "excluding moa\n",
      "excluding bewick's swan\n",
      "excluding gaviiform seabird\n",
      "excluding gaviiform seabird\n",
      "excluding pied-billed grebe\n",
      "excluding caprimulgiform bird\n",
      "excluding mother carey's chicken\n",
      "excluding sharp-tailed grouse\n",
      "excluding rose-colored starling\n",
      "excluding rhode island red\n",
      "excluding shorebird\n",
      "excluding red-shouldered hawk\n",
      "excluding honeycreeper\n",
      "excluding black-winged stilt\n",
      "excluding greyhen\n",
      "excluding procellariiform seabird\n",
      "excluding procellariiform seabird\n",
      "excluding red-backed sandpiper\n",
      "excluding swallow-tailed kite\n",
      "excluding gold-crowned kinglet\n",
      "excluding parula warbler\n",
      "excluding black-necked stilt\n",
      "excluding streptopelia turtur\n",
      "excluding streptopelia turtur\n",
      "excluding red-breasted nuthatch\n",
      "excluding wilson's snipe\n",
      "excluding audubon's caracara\n",
      "excluding red-eyed vireo\n",
      "excluding anseriform bird\n",
      "excluding sphenisciform seabird\n",
      "excluding sphenisciform seabird\n",
      "excluding saddlebill\n",
      "excluding red-necked grebe\n",
      "excluding ruby-crowned kinglet\n",
      "excluding vermillion flycatcher\n",
      "excluding white-rumped shrike\n",
      "excluding ern\n",
      "excluding quack-quack\n",
      "excluding clark's nutcracker\n",
      "excluding ring-necked pheasant\n",
      "excluding corncrake\n",
      "excluding yellow-breasted bunting\n",
      "excluding blue-headed vireo\n",
      "excluding barrow's goldeneye\n",
      "excluding antbird\n",
      "excluding resplendent quetzel\n",
      "excluding wren-tit\n",
      "excluding thick-billed murre\n",
      "excluding pin-tailed sandgrouse\n",
      "excluding pin-tailed sandgrouse\n",
      "excluding white-headed stilt\n",
      "excluding sinornis\n",
      "excluding painted sandgrouse\n",
      "excluding audubon's warbler\n",
      "excluding giant moa\n",
      "excluding yellow-shafted flicker\n",
      "excluding spotted antbird\n",
      "excluding afropavo\n",
      "excluding red-legged partridge\n",
      "excluding black-crowned night heron\n",
      "excluding yellow-breasted chat\n",
      "excluding podicipitiform seabird\n",
      "excluding podicipitiform seabird\n",
      "excluding rough-legged hawk\n",
      "excluding meadowlark\n",
      "excluding archilochus colubris\n",
      "excluding archilochus colubris\n",
      "excluding black-necked grebe\n",
      "excluding cooper's hawk\n",
      "excluding oystercatcher\n",
      "excluding euopean hoopoe\n",
      "excluding red-breasted merganser\n",
      "excluding ring-necked parakeet\n",
      "excluding whydah\n",
      "excluding ivorybill\n",
      "excluding sandgrouse\n",
      "excluding montagu's harrier\n",
      "excluding bushtit\n",
      "excluding sulphur-crested cockatoo\n",
      "excluding black-capped chickadee\n",
      "excluding flycatching warbler\n",
      "excluding moorhen\n",
      "excluding bullock's oriole\n",
      "excluding pelecaniform seabird\n",
      "excluding pelecaniform seabird\n",
      "excluding apodiform bird\n",
      "excluding black-backed gull\n",
      "excluding black-fronted bush shrike\n",
      "excluding chuck-will's-widow\n",
      "excluding white-tailed kite\n",
      "excluding tyrannid\n",
      "excluding homing pigeon\n",
      "excluding grassfinch\n",
      "excluding wilson's warbler\n",
      "excluding white-breasted nuthatch\n",
      "excluding red-breasted snipe\n",
      "excluding greylag\n",
      "excluding long-eared owl\n",
      "excluding columbiform bird\n",
      "excluding white-throated sparrow\n",
      "excluding fig-bird\n",
      "excluding cream-colored courser\n",
      "excluding pallas's sandgrouse\n",
      "excluding pallas's sandgrouse\n",
      "excluding black-footed albatross\n",
      "excluding white-crowned sparrow\n",
      "excluding moorcock\n",
      "excluding black-billed cuckoo\n",
      "excluding falcon-gentle\n",
      "excluding seabird\n",
      "excluding white-bellied swallow\n",
      "excluding green-tailed towhee\n",
      "excluding red-winged blackbird\n",
      "excluding band-tailed pigeon\n",
      "excluding currawong\n",
      "excluding white-chinned petrel\n",
      "excluding woodhewer\n",
      "excluding yellow-bellied sapsucker\n",
      "excluding tiercel\n",
      "excluding accipitriformes\n",
      "excluding cassin's kingbird\n",
      "excluding hardtop\n",
      "excluding minicar\n",
      "excluding minicab\n",
      "excluding hatchback\n",
      "excluding subcompact\n",
      "excluding minivan\n",
      "excluding used-car\n",
      "excluding propjet\n",
      "excluding airbus\n",
      "excluding fanjet\n",
      "excluding widebody aircraft\n",
      "excluding ski-plane\n",
      "excluding double-prop\n",
      "excluding jetliner\n",
      "excluding narrowbody aircraft\n",
      "excluding jumbojet\n",
      "excluding twinjet\n",
      "excluding minivan\n",
      "excluding car-ferry\n",
      "excluding blockade-runner\n",
      "excluding guided missile frigate\n",
      "excluding pt boat\n",
      "excluding torpedo-boat destroyer\n",
      "excluding minelayer\n",
      "excluding minesweeper\n",
      "excluding nuclear-powered ship\n",
      "excluding gas-turbine ship\n",
      "excluding man-of-war\n",
      "excluding sternwheeler\n",
      "excluding cattleship\n",
      "excluding guided missile cruiser\n",
      "excluding mailboat\n",
      "excluding side-wheeler\n",
      "excluding supertanker\n",
      "excluding fire-bellied toad\n",
      "excluding eastern narrow-mouthed toad\n",
      "excluding cascades frog\n",
      "excluding yosemite toad\n",
      "excluding leptodactylid frog\n",
      "excluding lowland burrowing treefrog\n",
      "excluding lowland burrowing treefrog\n",
      "excluding western narrow-mouthed toad\n",
      "excluding wood-frog\n",
      "excluding liopelma hamiltoni\n",
      "excluding liopelma hamiltoni\n",
      "excluding canyon treefrog\n",
      "excluding plains spadefoot\n",
      "excluding jaguarundi\n",
      "excluding packhorse\n",
      "excluding lippizan\n",
      "excluding warrigal\n",
      "excluding two-year-old horse\n",
      "excluding three-year-old horse\n",
      "excluding appaloosa\n",
      "excluding mudder\n",
      "excluding racehorse\n",
      "excluding gee-gee\n",
      "excluding przewalski's horse\n",
      "excluding tennessee walker\n",
      "excluding stablemate\n",
      "excluding carthorse\n",
      "excluding trotting horse\n",
      "excluding broodmare\n",
      "excluding gazella subgutturosa\n",
      "excluding thomson's gazelle\n",
      "excluding waterbuck\n",
      "excluding mountain nyala\n",
      "excluding pere david's deer\n",
      "excluding pere david's deer\n",
      "excluding dik-dik\n",
      "excluding harnessed antelope\n",
      "excluding blackbuck\n",
      "excluding black-tailed deer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 160.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "bird\n",
      "automobile\n",
      "airplane\n",
      "truck\n",
      "ship\n",
      "frog\n",
      "cat\n",
      "horse\n",
      "deer\n",
      "reference\n",
      "0.6642218046323067\n",
      "performing classify captions on svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 9/9 [00:00<00:00, 28.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.73it/s]\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "100%|██████████| 10/10 [00:00<00:00, 28.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg_captions': array(['a photo of a red bomber', 'a photo of a red bomber inside',\n",
      "       'a photo of a red reconnaissance plane inside',\n",
      "       'a photo of a red bomber in the air',\n",
      "       'a photo of a red reconnaissance plane',\n",
      "       'a photo of a red bomber flying',\n",
      "       'a photo of a red bomber outside',\n",
      "       'a photo of a red reconnaissance plane outside',\n",
      "       'a photo of a red dive bomber inside',\n",
      "       'a photo of a red dive bomber'], dtype='<U62'),\n",
      " 'neg_latents': array([[ 0.4033203 ,  0.3310547 ,  0.12005615, ..., -0.29614258,\n",
      "        -0.16247559, -0.15063477],\n",
      "       [ 0.17163086,  0.28735352, -0.00491714, ..., -0.13024902,\n",
      "        -0.01203918, -0.10223389],\n",
      "       [ 0.08837891,  0.19189453,  0.06976318, ...,  0.16992188,\n",
      "         0.11950684, -0.14941406],\n",
      "       ...,\n",
      "       [ 0.18774414,  0.22155762,  0.19665527, ...,  0.11187744,\n",
      "         0.05444336, -0.15112305],\n",
      "       [ 0.22802734, -0.00438309, -0.09326172, ...,  0.24707031,\n",
      "         0.25146484,  0.05679321],\n",
      "       [ 0.45117188,  0.05477905, -0.03485107, ...,  0.08654785,\n",
      "         0.20861816, -0.03692627]], dtype=float32),\n",
      " 'neg_vals': array([-0.60616925, -0.59245537, -0.49926288, -0.4959516 , -0.49378589,\n",
      "       -0.49118785, -0.46485648, -0.46058038, -0.44178772, -0.40964066]),\n",
      " 'pos_captions': array(['a photo of a black jet on a white background',\n",
      "       'a photo of a black airliner on a white background',\n",
      "       'a photo of a black airliner', 'a photo of a black airplane',\n",
      "       'a photo of a black airplane on a white background',\n",
      "       'a photo of a black airliner on the tarmac',\n",
      "       'a photo of a black jet on a blue background',\n",
      "       'a photo of a black airliner in the air',\n",
      "       'a photo of a black stealth fighter on a white background',\n",
      "       'a photo of a black airliner outside'], dtype='<U62'),\n",
      " 'pos_latents': array([[ 3.2983398e-01,  9.3383789e-02, -2.7026367e-01, ...,\n",
      "         1.8402100e-02,  1.4331055e-01, -4.8413086e-01],\n",
      "       [ 2.8198242e-01,  6.9946289e-02, -4.4018555e-01, ...,\n",
      "         1.5258789e-01,  2.3681641e-01, -5.0878906e-01],\n",
      "       [ 3.4814453e-01,  2.7539062e-01, -1.9750977e-01, ...,\n",
      "         6.8420410e-02,  2.7148438e-01, -6.5734863e-02],\n",
      "       ...,\n",
      "       [ 3.9282227e-01,  3.0419922e-01, -2.6879883e-01, ...,\n",
      "         7.8491211e-02,  3.7524414e-01, -1.7053223e-01],\n",
      "       [ 1.0357666e-01, -1.0662842e-01, -3.6716461e-04, ...,\n",
      "         3.1616211e-01,  1.7980957e-01, -5.4638672e-01],\n",
      "       [ 3.1762695e-01,  3.3984375e-01, -2.2790527e-01, ...,\n",
      "         6.8481445e-02,  3.6816406e-01, -7.2875977e-02]], dtype=float32),\n",
      " 'pos_vals': array([1.2189884 , 1.20812869, 1.17615242, 1.1750145 , 1.13749887,\n",
      "       1.13397957, 1.1291831 , 1.11241206, 1.10762546, 1.09634087])}\n",
      "--------\n",
      "pos: a photo of a black jet on a white background\n",
      "neg: a photo of a red bomber\n",
      "0.7010094305812045\n",
      "performing classify captions on svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 28.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 134.76it/s]\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "100%|██████████| 10/10 [00:00<00:00, 27.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg_captions': array(['a photo of a ambulance', 'a photo of a ambulance outside',\n",
      "       'a photo of a ambulance inside', 'a photo of a ambulance parked',\n",
      "       'a photo of a brown ambulance inside',\n",
      "       'a photo of a brown ambulance outside',\n",
      "       'a photo of a brown ambulance',\n",
      "       'a photo of a white ambulance inside',\n",
      "       'a photo of a white ambulance outside', 'a photo of a stock car'],\n",
      "      dtype='<U60'),\n",
      " 'neg_latents': array([[ 0.12438965,  0.26489258,  0.05358887, ..., -0.42651367,\n",
      "        -0.22302246, -0.23632812],\n",
      "       [ 0.04193115,  0.35375977,  0.12487793, ..., -0.42138672,\n",
      "        -0.19482422, -0.1809082 ],\n",
      "       [ 0.02941895,  0.22436523, -0.01295471, ..., -0.36132812,\n",
      "        -0.04232788, -0.23461914],\n",
      "       ...,\n",
      "       [-0.04595947,  0.05499268,  0.15649414, ..., -0.2631836 ,\n",
      "        -0.17602539, -0.4020996 ],\n",
      "       [-0.03607178,  0.14196777,  0.24609375, ..., -0.27441406,\n",
      "        -0.25610352, -0.37060547],\n",
      "       [-0.00453568,  0.12768555, -0.25024414, ...,  0.35253906,\n",
      "        -0.52246094,  0.15429688]], dtype=float32),\n",
      " 'neg_vals': array([-1.16296413, -1.14322042, -1.10894518, -1.08985804, -1.0150497 ,\n",
      "       -1.00968541, -1.00922231, -0.9966207 , -0.9919969 , -0.9883018 ]),\n",
      " 'pos_captions': array(['a photo of a black sedan',\n",
      "       'a photo of a black sedan on a blue background',\n",
      "       'a photo of a blue sedan on a black background',\n",
      "       'a photo of a blue sedan',\n",
      "       'a photo of a red sedan on a black background',\n",
      "       'a photo of a red sedan',\n",
      "       'a photo of a red sedan on a blue background',\n",
      "       'a photo of a black pace car',\n",
      "       'a photo of a black sedan on a black background',\n",
      "       'a photo of a blue pace car on a black background'], dtype='<U60'),\n",
      " 'pos_latents': array([[ 0.4951172 ,  0.23120117,  0.03671265, ...,  0.16394043,\n",
      "        -0.0256958 , -0.1262207 ],\n",
      "       [ 0.4970703 , -0.00136375, -0.29174805, ...,  0.21643066,\n",
      "        -0.09527588,  0.04089355],\n",
      "       [ 0.19848633,  0.06549072, -0.18518066, ...,  0.16479492,\n",
      "        -0.30395508, -0.04519653],\n",
      "       ...,\n",
      "       [ 0.3125    , -0.09881592, -0.19006348, ...,  0.3088379 ,\n",
      "        -0.01473236,  0.45385742],\n",
      "       [ 0.2890625 ,  0.19812012, -0.13415527, ...,  0.15161133,\n",
      "        -0.03250122, -0.21154785],\n",
      "       [ 0.18676758, -0.09509277, -0.296875  , ...,  0.42529297,\n",
      "        -0.26782227,  0.39819336]], dtype=float32),\n",
      " 'pos_vals': array([-0.42229594, -0.42713587, -0.42890158, -0.42945929, -0.4311195 ,\n",
      "       -0.43112759, -0.43124922, -0.44088053, -0.44246762, -0.4491877 ])}\n",
      "--------\n",
      "pos: a photo of a black sedan\n",
      "neg: a photo of a ambulance\n",
      "0.6696851119624674\n",
      "performing classify captions on svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:09<00:00, 27.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.54it/s]\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg_captions': array(['a photo of a white oscine inside',\n",
      "       'a photo of a white twitterer inside',\n",
      "       'a photo of a white twitterer flying',\n",
      "       'a photo of a honey guide inside',\n",
      "       'a photo of a orange twitterer inside',\n",
      "       'a photo of a white honey guide inside',\n",
      "       'a photo of a twitterer flying',\n",
      "       'a photo of a white oscine in the air',\n",
      "       'a photo of a red twitterer inside', 'a photo of a cackler inside'],\n",
      "      dtype='<U65'),\n",
      " 'neg_latents': array([[-0.19812012,  0.35253906, -0.18237305, ..., -0.22497559,\n",
      "        -0.00176239, -0.14990234],\n",
      "       [-0.19262695, -0.24230957, -0.13208008, ..., -0.28979492,\n",
      "        -0.1194458 ,  0.04562378],\n",
      "       [ 0.20727539,  0.26586914, -0.18103027, ..., -0.27563477,\n",
      "         0.1315918 , -0.5126953 ],\n",
      "       ...,\n",
      "       [ 0.0612793 ,  0.29370117, -0.21142578, ..., -0.28149414,\n",
      "         0.0871582 , -0.5449219 ],\n",
      "       [-0.1829834 , -0.08105469, -0.21484375, ..., -0.34960938,\n",
      "        -0.05825806,  0.2932129 ],\n",
      "       [-0.12927246,  0.26733398,  0.02963257, ..., -0.35302734,\n",
      "        -0.03927612,  0.25268555]], dtype=float32),\n",
      " 'neg_vals': array([-2.74412908, -2.55068196, -2.53945436, -2.48602723, -2.45946771,\n",
      "       -2.45171657, -2.4040857 , -2.39376001, -2.3733571 , -2.37077517]),\n",
      " 'pos_captions': array(['a photo of a blue black grouse',\n",
      "       'a photo of a blue asian black grouse',\n",
      "       'a photo of a brown purple grackle outside',\n",
      "       'a photo of a black purple grackle outside',\n",
      "       'a photo of a blue black grouse outside',\n",
      "       'a photo of a brown purple grackle',\n",
      "       'a photo of a blue asian black grouse outside',\n",
      "       'a photo of a blue black grouse perched',\n",
      "       'a photo of a black asian black grouse',\n",
      "       'a photo of a black purple grackle'], dtype='<U65'),\n",
      " 'pos_latents': array([[ 0.234375  ,  0.15185547, -0.24609375, ...,  0.5864258 ,\n",
      "        -0.35131836, -0.2368164 ],\n",
      "       [ 0.2368164 ,  0.17089844, -0.15905762, ...,  0.52490234,\n",
      "        -0.3581543 , -0.41308594],\n",
      "       [ 0.46484375,  0.22180176,  0.05871582, ...,  0.62109375,\n",
      "         0.18432617, -0.14123535],\n",
      "       ...,\n",
      "       [ 0.15429688,  0.07983398, -0.22387695, ...,  0.53466797,\n",
      "        -0.33862305, -0.30786133],\n",
      "       [ 0.23059082,  0.24365234, -0.17736816, ...,  0.42138672,\n",
      "        -0.26098633, -0.4519043 ],\n",
      "       [ 0.4711914 ,  0.1430664 , -0.00827789, ...,  0.6479492 ,\n",
      "         0.22058105, -0.05947876]], dtype=float32),\n",
      " 'pos_vals': array([-0.50186855, -0.52468737, -0.52645127, -0.53479991, -0.53512262,\n",
      "       -0.53707385, -0.54354902, -0.54699467, -0.54837621, -0.54951212])}\n",
      "--------\n",
      "pos: a photo of a blue black grouse\n",
      "neg: a photo of a white oscine inside\n",
      "0.6415698284604889\n",
      "performing classify captions on svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 25.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.13it/s]\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "100%|██████████| 10/10 [00:00<00:00, 20.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg_captions': array(['a photo of a white mouser on the grass',\n",
      "       'a photo of a blue mouser on the grass',\n",
      "       'a photo of a white ocelot on the grass',\n",
      "       'a photo of a green mouser on the grass',\n",
      "       'a photo of a blue ocelot on the grass',\n",
      "       'a photo of a red mouser on the grass',\n",
      "       'a photo of a white cougar on the grass',\n",
      "       'a photo of a green cougar on the grass',\n",
      "       'a photo of a blue cougar on the grass',\n",
      "       'a photo of a white persian cat on the grass'], dtype='<U60'),\n",
      " 'neg_latents': array([[-0.22460938, -0.33374023,  0.10137939, ..., -0.07196045,\n",
      "        -0.24133301, -0.09991455],\n",
      "       [-0.10229492, -0.3071289 ,  0.01446533, ..., -0.12573242,\n",
      "        -0.2783203 ,  0.24780273],\n",
      "       [-0.16906738, -0.4230957 , -0.13537598, ...,  0.3215332 ,\n",
      "        -0.22241211,  0.01625061],\n",
      "       ...,\n",
      "       [ 0.05981445, -0.1048584 , -0.03503418, ..., -0.09448242,\n",
      "        -0.08703613,  0.28955078],\n",
      "       [ 0.02685547, -0.24157715, -0.04205322, ...,  0.0061264 ,\n",
      "        -0.23742676,  0.3317871 ],\n",
      "       [ 0.06433105, -0.20324707, -0.00550461, ...,  0.4255371 ,\n",
      "        -0.16052246, -0.20361328]], dtype=float32),\n",
      " 'neg_vals': array([-1.35763915, -1.3161681 , -1.31086526, -1.28679693, -1.28454509,\n",
      "       -1.26950532, -1.26372996, -1.24960842, -1.23557197, -1.22458792]),\n",
      " 'pos_captions': array(['a photo of a brown domestic cat inside',\n",
      "       'a photo of a black tabby', 'a photo of a brown tabby',\n",
      "       'a photo of a brown domestic cat',\n",
      "       'a photo of a brown tabby inside',\n",
      "       'a photo of a black domestic cat inside',\n",
      "       'a photo of a black tabby inside',\n",
      "       'a photo of a black domestic cat',\n",
      "       'a photo of a brown domestic cat in a house',\n",
      "       'a photo of a brown tabby in a house'], dtype='<U60'),\n",
      " 'pos_latents': array([[ 0.16809082, -0.03894043, -0.02893066, ...,  0.15661621,\n",
      "        -0.5307617 ,  0.04190063],\n",
      "       [ 0.13964844,  0.06640625, -0.19030762, ..., -0.17285156,\n",
      "        -0.43896484,  0.09558105],\n",
      "       [-0.08398438,  0.20300293, -0.01340485, ..., -0.06854248,\n",
      "        -0.5727539 , -0.05511475],\n",
      "       ...,\n",
      "       [ 0.38842773, -0.0475769 , -0.1895752 , ...,  0.27539062,\n",
      "        -0.29711914, -0.00124836],\n",
      "       [ 0.2783203 ,  0.05789185, -0.14025879, ...,  0.41015625,\n",
      "        -0.2734375 ,  0.0104599 ],\n",
      "       [ 0.06152344,  0.08990479, -0.23840332, ...,  0.15734863,\n",
      "        -0.38867188, -0.02731323]], dtype=float32),\n",
      " 'pos_vals': array([0.19651501, 0.19357323, 0.16439072, 0.16348092, 0.14113811,\n",
      "       0.12921414, 0.12806636, 0.0956767 , 0.09337969, 0.06935198])}\n",
      "--------\n",
      "pos: a photo of a brown domestic cat inside\n",
      "neg: a photo of a white mouser on the grass\n",
      "0.6484821828610479\n",
      "performing classify captions on svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 28.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 132.64it/s]\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg_captions': array(['a photo of a kob inside', 'a photo of a kob',\n",
      "       'a photo of a sassaby', 'a photo of a white kob in the snow',\n",
      "       'a photo of a kob in the snow', 'a photo of a white kob inside',\n",
      "       'a photo of a sassaby inside',\n",
      "       'a photo of a white sassaby in the snow',\n",
      "       'a photo of a sassaby outside', 'a photo of a sassaby in the snow'],\n",
      "      dtype='<U63'),\n",
      " 'neg_latents': array([[-0.21325684,  0.21948242, -0.04556274, ..., -0.5048828 ,\n",
      "        -0.13024902,  0.2397461 ],\n",
      "       [-0.1430664 ,  0.2956543 ,  0.08148193, ..., -0.63916016,\n",
      "        -0.24694824,  0.22277832],\n",
      "       [-0.24768066,  0.00634003, -0.10797119, ..., -0.828125  ,\n",
      "        -0.08276367, -0.27929688],\n",
      "       ...,\n",
      "       [-0.1796875 , -0.01174164,  0.03137207, ..., -0.6254883 ,\n",
      "        -0.01927185, -0.93359375],\n",
      "       [-0.24414062,  0.0927124 , -0.07055664, ..., -0.88378906,\n",
      "        -0.09381104, -0.26635742],\n",
      "       [-0.25317383,  0.02832031, -0.07012939, ..., -0.8955078 ,\n",
      "         0.17578125, -0.7504883 ]], dtype=float32),\n",
      " 'neg_vals': array([-1.24900969, -1.23362051, -1.23071396, -1.21969163, -1.21822964,\n",
      "       -1.19208915, -1.18009391, -1.1419804 , -1.1330799 , -1.12927756]),\n",
      " 'pos_captions': array(['a photo of a wapiti in a forest',\n",
      "       'a photo of a green wapiti in a forest',\n",
      "       'a photo of a green red deer outside',\n",
      "       'a photo of a green red deer in a forest',\n",
      "       'a photo of a black wapiti in a forest',\n",
      "       'a photo of a wapiti on a green background',\n",
      "       'a photo of a orange wapiti in a forest',\n",
      "       'a photo of a yellow wapiti in a forest',\n",
      "       'a photo of a green wapiti outside',\n",
      "       'a photo of a green wapiti on a green background'], dtype='<U63'),\n",
      " 'pos_latents': array([[-0.14074707,  0.27612305,  0.09283447, ...,  0.30859375,\n",
      "        -0.01257324,  0.30688477],\n",
      "       [-0.07995605,  0.3076172 , -0.04196167, ...,  0.31103516,\n",
      "        -0.06567383,  0.41088867],\n",
      "       [ 0.08502197,  0.31835938,  0.16577148, ...,  0.04589844,\n",
      "         0.01756287,  0.02664185],\n",
      "       ...,\n",
      "       [ 0.02616882,  0.32543945, -0.08062744, ...,  0.4584961 ,\n",
      "         0.16271973,  0.18591309],\n",
      "       [-0.03833008,  0.2163086 , -0.05770874, ...,  0.2536621 ,\n",
      "        -0.06884766,  0.08959961],\n",
      "       [-0.09454346,  0.03515625, -0.20397949, ...,  0.3605957 ,\n",
      "         0.05050659,  0.13208008]], dtype=float32),\n",
      " 'pos_vals': array([0.41086241, 0.38389887, 0.35014086, 0.34481778, 0.33690271,\n",
      "       0.31662894, 0.3046753 , 0.29105636, 0.28956101, 0.27709467])}\n",
      "--------\n",
      "pos: a photo of a wapiti in a forest\n",
      "neg: a photo of a kob inside\n",
      "0.6876278118609407\n",
      "performing classify captions on svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:02<00:00, 26.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.71it/s]\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg_captions': array(['a photo of a black feist', 'a photo of a black feist outside',\n",
      "       'a photo of a feist', 'a photo of a black mexican hairless inside',\n",
      "       'a photo of a brown feist', 'a photo of a black mexican hairless',\n",
      "       'a photo of a brown mexican hairless inside',\n",
      "       'a photo of a black mexican hairless outside',\n",
      "       'a photo of a black feist inside', 'a photo of a green feist'],\n",
      "      dtype='<U69'),\n",
      " 'neg_latents': array([[ 0.12158203, -0.13012695, -0.18444824, ..., -0.18847656,\n",
      "        -0.08825684,  0.34472656],\n",
      "       [ 0.17443848, -0.03068542, -0.17297363, ..., -0.11096191,\n",
      "        -0.02459717,  0.29467773],\n",
      "       [-0.04125977, -0.03536987, -0.18225098, ..., -0.43969727,\n",
      "        -0.17810059,  0.35595703],\n",
      "       ...,\n",
      "       [ 0.01129913, -0.0259552 , -0.17626953, ...,  0.24804688,\n",
      "         0.11456299, -0.08331299],\n",
      "       [ 0.12573242, -0.21240234, -0.27001953, ..., -0.22253418,\n",
      "        -0.08129883,  0.45117188],\n",
      "       [ 0.014534  , -0.12512207, -0.30639648, ..., -0.23803711,\n",
      "        -0.18969727,  0.49389648]], dtype=float32),\n",
      " 'neg_vals': array([-2.98782852, -2.91153139, -2.86755097, -2.86308772, -2.8480948 ,\n",
      "       -2.8304729 , -2.80096622, -2.77687039, -2.77249042, -2.76714954]),\n",
      " 'pos_captions': array(['a photo of a white saint bernard inside',\n",
      "       'a photo of a white saint bernard outside',\n",
      "       'a photo of a white saint bernard in a house',\n",
      "       'a photo of a white saint bernard',\n",
      "       'a photo of a white saint bernard on the grass',\n",
      "       'a photo of a red saint bernard on the grass',\n",
      "       'a photo of a red saint bernard in a house',\n",
      "       'a photo of a red saint bernard inside',\n",
      "       'a photo of a white tibetan terrier in a house',\n",
      "       'a photo of a white tibetan terrier inside'], dtype='<U69'),\n",
      " 'pos_latents': array([[-0.02359009,  0.18713379, -0.12731934, ...,  0.15490723,\n",
      "        -0.11236572, -0.24890137],\n",
      "       [-0.02348328,  0.27539062, -0.10314941, ...,  0.16833496,\n",
      "        -0.12164307, -0.25561523],\n",
      "       [ 0.15637207,  0.25390625, -0.20751953, ...,  0.34716797,\n",
      "        -0.0463562 , -0.23425293],\n",
      "       ...,\n",
      "       [ 0.03289795,  0.35888672, -0.18859863, ...,  0.08319092,\n",
      "        -0.15625   , -0.05911255],\n",
      "       [ 0.18200684,  0.1451416 , -0.4128418 , ...,  0.49145508,\n",
      "        -0.10687256, -0.15026855],\n",
      "       [-0.08477783,  0.0847168 , -0.4038086 , ...,  0.36132812,\n",
      "        -0.23925781, -0.12976074]], dtype=float32),\n",
      " 'pos_vals': array([-1.04041746, -1.06527334, -1.06846104, -1.06999672, -1.08939785,\n",
      "       -1.14236962, -1.14688163, -1.14816436, -1.14971493, -1.15210817])}\n",
      "--------\n",
      "pos: a photo of a white saint bernard inside\n",
      "neg: a photo of a black feist\n",
      "0.6769806482669898\n",
      "performing classify captions on svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 25.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 121.73it/s]\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "100%|██████████| 10/10 [00:00<00:00, 14.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg_captions': array(['a photo of a agua', 'a photo of a agua inside',\n",
      "       'a photo of a agua outside', 'a photo of a black agua inside',\n",
      "       'a photo of a black agua', 'a photo of a black agua outside',\n",
      "       'a photo of a brown agua', 'a photo of a brown agua inside',\n",
      "       'a photo of a white agua inside',\n",
      "       'a photo of a brown agua outside'], dtype='<U68'),\n",
      " 'neg_latents': array([[-0.15551758,  0.38793945,  0.18383789, ..., -0.27148438,\n",
      "         0.03216553,  0.05941772],\n",
      "       [-0.22351074,  0.43310547,  0.1282959 , ..., -0.27783203,\n",
      "         0.12469482, -0.04089355],\n",
      "       [-0.17822266,  0.54785156,  0.14880371, ..., -0.26904297,\n",
      "         0.12731934,  0.09912109],\n",
      "       ...,\n",
      "       [-0.05691528,  0.5541992 ,  0.08105469, ..., -0.26635742,\n",
      "         0.05380249, -0.1352539 ],\n",
      "       [-0.3310547 ,  0.39892578,  0.234375  , ..., -0.25219727,\n",
      "         0.1451416 , -0.24023438],\n",
      "       [ 0.01754761,  0.54296875,  0.04727173, ..., -0.20349121,\n",
      "        -0.02075195, -0.14465332]], dtype=float32),\n",
      " 'neg_vals': array([-1.14661871, -1.12354135, -1.11009631, -1.06665935, -1.02155496,\n",
      "       -1.01822686, -1.01245273, -1.00974975, -0.9938648 , -0.98323106]),\n",
      " 'pos_captions': array(['a photo of a green chameleon tree frog',\n",
      "       'a photo of a chameleon tree frog',\n",
      "       'a photo of a yellow chameleon tree frog',\n",
      "       'a photo of a yellow bufo', 'a photo of a yellow bufo outside',\n",
      "       'a photo of a yellow chameleon tree frog inside',\n",
      "       'a photo of a white chameleon tree frog',\n",
      "       'a photo of a yellow bufo inside',\n",
      "       'a photo of a yellow leopard frog inside',\n",
      "       'a photo of a yellow chameleon tree frog outside'], dtype='<U68'),\n",
      " 'pos_latents': array([[ 0.18225098,  0.23156738, -0.0668335 , ...,  0.4428711 ,\n",
      "         0.07922363,  0.0328064 ],\n",
      "       [ 0.21875   ,  0.3005371 , -0.05795288, ...,  0.265625  ,\n",
      "         0.10089111, -0.02841187],\n",
      "       [ 0.25195312,  0.15515137, -0.17651367, ...,  0.49560547,\n",
      "         0.24121094,  0.00651932],\n",
      "       ...,\n",
      "       [ 0.0769043 ,  0.09014893, -0.02153015, ...,  0.24743652,\n",
      "         0.07208252,  0.08453369],\n",
      "       [-0.29541016,  0.07983398, -0.12548828, ...,  0.4892578 ,\n",
      "         0.12878418, -0.03256226],\n",
      "       [ 0.29492188,  0.12420654, -0.11523438, ...,  0.61083984,\n",
      "         0.3413086 ,  0.09814453]], dtype=float32),\n",
      " 'pos_vals': array([-0.18036804, -0.18059905, -0.18074194, -0.19532672, -0.19877815,\n",
      "       -0.20849333, -0.2092747 , -0.21178091, -0.21990906, -0.22142768])}\n",
      "--------\n",
      "pos: a photo of a green chameleon tree frog\n",
      "neg: a photo of a agua\n",
      "0.6935678717699402\n",
      "performing classify captions on svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 29.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 114.39it/s]\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "100%|██████████| 10/10 [00:00<00:00, 18.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg_captions': array(['a photo of a protohippus inside',\n",
      "       'a photo of a blue eohippus inside', 'a photo of a blue eohippus',\n",
      "       'a photo of a wild horse', 'a photo of a white eohippus inside',\n",
      "       'a photo of a blue steed inside', 'a photo of a eohippus inside',\n",
      "       'a photo of a blue tarpan inside',\n",
      "       'a photo of a green eohippus inside', 'a photo of a protohippus'],\n",
      "      dtype='<U63'),\n",
      " 'neg_latents': array([[-0.19116211,  0.33618164, -0.37451172, ..., -0.17797852,\n",
      "        -0.23901367, -0.25439453],\n",
      "       [-0.3017578 ,  0.00455856, -0.09680176, ..., -0.07965088,\n",
      "        -0.12585449,  0.171875  ],\n",
      "       [-0.20568848,  0.07617188,  0.11871338, ...,  0.05502319,\n",
      "        -0.10473633,  0.10803223],\n",
      "       ...,\n",
      "       [-0.19360352,  0.21838379,  0.0096817 , ..., -0.04486084,\n",
      "        -0.46240234,  0.0647583 ],\n",
      "       [-0.3527832 ,  0.09997559, -0.28759766, ..., -0.0567627 ,\n",
      "         0.0411377 ,  0.2241211 ],\n",
      "       [ 0.01934814,  0.4567871 , -0.28881836, ..., -0.15075684,\n",
      "        -0.2241211 , -0.21069336]], dtype=float32),\n",
      " 'neg_vals': array([0.1136522 , 0.15805785, 0.21194506, 0.2150186 , 0.22519523,\n",
      "       0.240276  , 0.24853107, 0.25130316, 0.27128461, 0.27509517]),\n",
      " 'pos_captions': array(['a photo of a black steeplechaser outside',\n",
      "       'a photo of a black prancer outside',\n",
      "       'a photo of a black pinto outside', 'a photo of a black pinto',\n",
      "       'a photo of a black palfrey in a field',\n",
      "       'a photo of a black mare outside',\n",
      "       'a photo of a red prancer outside',\n",
      "       'a photo of a harness horse outside', 'a photo of a black prancer',\n",
      "       'a photo of a black prancer inside'], dtype='<U63'),\n",
      " 'pos_latents': array([[-0.06396484,  0.46826172, -0.23364258, ..., -0.14196777,\n",
      "         0.07952881, -0.12939453],\n",
      "       [ 0.48217773,  0.03564453, -0.1484375 , ...,  0.05667114,\n",
      "         0.12902832,  0.18676758],\n",
      "       [ 0.20422363,  0.3059082 , -0.109375  , ...,  0.13574219,\n",
      "        -0.02648926, -0.03286743],\n",
      "       ...,\n",
      "       [-0.18713379,  0.1517334 ,  0.1307373 , ...,  0.68310547,\n",
      "        -0.2397461 ,  0.11224365],\n",
      "       [ 0.47851562, -0.02456665, -0.08978271, ...,  0.02616882,\n",
      "         0.04962158,  0.20080566],\n",
      "       [ 0.5151367 , -0.13085938, -0.18774414, ..., -0.07250977,\n",
      "         0.08453369,  0.23852539]], dtype=float32),\n",
      " 'pos_vals': array([1.49443623, 1.45187188, 1.44308282, 1.43935612, 1.39406485,\n",
      "       1.34965079, 1.34114977, 1.32645815, 1.32090029, 1.30116499])}\n",
      "--------\n",
      "pos: a photo of a black steeplechaser outside\n",
      "neg: a photo of a protohippus inside\n",
      "0.6241176656968883\n",
      "performing classify captions on svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:01<00:00, 27.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 110.28it/s]\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg_captions': array(['a photo of a racing gig', 'a photo of a blue racing gig outside',\n",
      "       'a photo of a racing gig outside', 'a photo of a blue racing gig',\n",
      "       'a photo of a racing gig inside',\n",
      "       'a photo of a blue racing gig inside',\n",
      "       'a photo of a blue sloop of war outside',\n",
      "       'a photo of a white racing gig outside',\n",
      "       'a photo of a blue racing gig on the horizon',\n",
      "       'a photo of a blue sloop of war'], dtype='<U75'),\n",
      " 'neg_latents': array([[ 0.2331543 ,  0.05691528,  0.03704834, ...,  0.11865234,\n",
      "         0.07855225, -0.18457031],\n",
      "       [ 0.1973877 ,  0.05496216,  0.03317261, ..., -0.02108765,\n",
      "         0.10809326,  0.00676346],\n",
      "       [ 0.19897461,  0.0034771 ,  0.03433228, ..., -0.0254364 ,\n",
      "         0.21875   , -0.0423584 ],\n",
      "       ...,\n",
      "       [ 0.03034973,  0.02455139,  0.15991211, ..., -0.11199951,\n",
      "         0.15441895, -0.2890625 ],\n",
      "       [ 0.20385742, -0.01551056,  0.06518555, ...,  0.24902344,\n",
      "         0.07141113,  0.07067871],\n",
      "       [-0.11187744, -0.00756454, -0.12634277, ...,  0.1274414 ,\n",
      "        -0.01347351,  0.04354858]], dtype=float32),\n",
      " 'neg_vals': array([-0.96898084, -0.92984272, -0.92592069, -0.92536438, -0.91558504,\n",
      "       -0.9134962 , -0.89232399, -0.88927133, -0.88129813, -0.8755394 ]),\n",
      " 'pos_captions': array(['a photo of a brown tugboat outside',\n",
      "       'a photo of a brown tugboat docked',\n",
      "       'a photo of a brown transport ship docked',\n",
      "       'a photo of a brown factory ship docked',\n",
      "       'a photo of a brown small ship docked',\n",
      "       'a photo of a brown dredger docked', 'a photo of a brown tugboat',\n",
      "       'a photo of a brown guard ship docked',\n",
      "       'a photo of a brown fireboat outside',\n",
      "       'a photo of a sister ship in the water'], dtype='<U75'),\n",
      " 'pos_latents': array([[ 0.12988281,  0.14453125,  0.02558899, ...,  0.28564453,\n",
      "        -0.13134766, -0.18066406],\n",
      "       [ 0.2536621 ,  0.00819397,  0.12683105, ...,  0.36499023,\n",
      "        -0.17370605, -0.14282227],\n",
      "       [ 0.22485352, -0.02537537,  0.12561035, ...,  0.03866577,\n",
      "        -0.10974121, -0.29614258],\n",
      "       ...,\n",
      "       [ 0.14538574, -0.18127441,  0.14196777, ..., -0.00976562,\n",
      "         0.02227783, -0.21606445],\n",
      "       [ 0.02807617, -0.05593872,  0.13513184, ...,  0.24768066,\n",
      "        -0.3178711 , -0.03344727],\n",
      "       [ 0.18164062,  0.07977295,  0.15783691, ..., -0.16809082,\n",
      "         0.1328125 , -0.24768066]], dtype=float32),\n",
      " 'pos_vals': array([-0.2562699 , -0.26072156, -0.2710384 , -0.27111578, -0.27117215,\n",
      "       -0.27581352, -0.278645  , -0.28449114, -0.28669657, -0.28767299])}\n",
      "--------\n",
      "pos: a photo of a brown tugboat outside\n",
      "neg: a photo of a racing gig\n",
      "0.6601421725872243\n",
      "performing classify captions on svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 25.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 135.91it/s]\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "/mnt/cfs/home/saachij/src/failure-directions/analysis_nbs/../failure_directions/src/svm_utils.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  latents = torch.tensor(latents)\n",
      "100%|██████████| 10/10 [00:00<00:00, 38.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg_captions': array(['a photo of a white passenger van',\n",
      "       'a photo of a white passenger van inside',\n",
      "       'a photo of a white passenger van on the road',\n",
      "       'a photo of a white passenger van outside',\n",
      "       'a photo of a blue passenger van on the road',\n",
      "       'a photo of a blue passenger van',\n",
      "       'a photo of a brown passenger van on the road',\n",
      "       'a photo of a blue passenger van inside',\n",
      "       'a photo of a blue passenger van outside',\n",
      "       'a photo of a orange passenger van on the road'], dtype='<U56'),\n",
      " 'neg_latents': array([[ 0.0612793 ,  0.1538086 ,  0.15783691, ...,  0.25756836,\n",
      "        -0.05764771, -0.17041016],\n",
      "       [-0.0194397 ,  0.2244873 ,  0.05880737, ...,  0.19238281,\n",
      "        -0.02528381, -0.18786621],\n",
      "       [-0.0557251 ,  0.1685791 ,  0.14208984, ...,  0.25732422,\n",
      "         0.01333618, -0.16625977],\n",
      "       ...,\n",
      "       [ 0.18969727,  0.10583496, -0.03022766, ...,  0.28515625,\n",
      "        -0.11218262,  0.2331543 ],\n",
      "       [ 0.26245117,  0.11224365, -0.00561523, ...,  0.24023438,\n",
      "        -0.09716797,  0.2644043 ],\n",
      "       [-0.05026245,  0.34643555,  0.20812988, ...,  0.36254883,\n",
      "         0.08062744, -0.12768555]], dtype=float32),\n",
      " 'neg_vals': array([-1.61643095, -1.59970906, -1.58476945, -1.56477385, -1.56421077,\n",
      "       -1.5582175 , -1.52322902, -1.51729778, -1.51301668, -1.5055749 ]),\n",
      " 'pos_captions': array(['a photo of a technical', 'a photo of a black technical',\n",
      "       'a photo of a technical outside',\n",
      "       'a photo of a black technical outside',\n",
      "       'a photo of a garbage truck', 'a photo of a milk float outside',\n",
      "       'a photo of a milk float', 'a photo of a black milk float',\n",
      "       'a photo of a technical parked',\n",
      "       'a photo of a black milk float outside'], dtype='<U56'),\n",
      " 'pos_latents': array([[-0.10406494,  0.51123047, -0.27978516, ..., -0.50390625,\n",
      "        -0.34936523,  0.04867554],\n",
      "       [ 0.01832581,  0.36645508, -0.24621582, ..., -0.47045898,\n",
      "        -0.2524414 , -0.0625    ],\n",
      "       [-0.23657227,  0.6152344 , -0.14746094, ..., -0.5961914 ,\n",
      "        -0.3112793 , -0.02632141],\n",
      "       ...,\n",
      "       [-0.08544922,  0.20751953, -0.05249023, ...,  0.04318237,\n",
      "         0.03427124,  0.06671143],\n",
      "       [ 0.12213135,  0.39648438, -0.06939697, ..., -0.6401367 ,\n",
      "        -0.35009766,  0.0249176 ],\n",
      "       [-0.10186768,  0.25708008, -0.03314209, ...,  0.03018188,\n",
      "         0.12475586,  0.0526123 ]], dtype=float32),\n",
      " 'pos_vals': array([ 0.54077311,  0.36421471,  0.24720505,  0.13249488,  0.06711427,\n",
      "        0.06681073,  0.03413601,  0.01569296, -0.00241438, -0.00620065])}\n",
      "--------\n",
      "pos: a photo of a technical\n",
      "neg: a photo of a white passenger van\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot(data\u001b[38;5;241m=\u001b[39mcombined_df, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTop K\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrder\u001b[39m\u001b[38;5;124m'\u001b[39m, ax\u001b[38;5;241m=\u001b[39max, \n\u001b[1;32m     54\u001b[0m              hue_order\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPositive\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverall Class\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     55\u001b[0m             palette\u001b[38;5;241m=\u001b[39m[BLUE, RED, GRAY], ci\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# handles, labels = ax.get_legend_handles_labels()\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[43mlabels\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverall Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# ax.legend(handles=handles, labels=labels)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop K Test Images by Caption\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5986512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load flip interventions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e14120e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicles 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intensity</th>\n",
       "      <th>Flip</th>\n",
       "      <th>Base</th>\n",
       "      <th>Original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   intensity   Flip  Base  Original\n",
       "0        0.1  0.650  0.62      0.65\n",
       "1        0.2  0.626  0.62      0.65\n",
       "2        0.3  0.602  0.62      0.65"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = 18\n",
    "print(class_names[cls])\n",
    "flip_interventions = torch.load(f\"/mnt/cfs/home/saachij/src/failure-directions/failure_directions/cifar100_sd_{cls}.pt\")\n",
    "\n",
    "df = []\n",
    "for intensity in [0.1, 0.2, 0.3]:\n",
    "    load_corrects = {\n",
    "        'flip': [(flip_interventions[intensity][u][0] == flip_interventions[intensity][u][1]) for u in range(len(flip_interventions[intensity]))],\n",
    "        'base': [(flip_interventions[0][u][0] == flip_interventions[0][u][1]) for u in range(len(flip_interventions[0]))],\n",
    "    #     'none': [(no_intervention[u][0] == no_intervention[u][1]) for u in range(5)],\n",
    "\n",
    "    }\n",
    "\n",
    "    mask = (test_problematic & (test_superclass == cls))\n",
    "    df.append([intensity,\n",
    "        np.mean([load_corrects['flip'][u][mask].float().mean().item() for u in range(5)]), \n",
    "        np.mean([load_corrects['base'][u][mask].float().mean().item() for u in range(5)]),\n",
    "          test_correct[mask].mean(),\n",
    "              ])\n",
    "df = pd.DataFrame(df, columns=['intensity', 'Flip', 'Base', \"Original\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0a8d89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6899999976158142,\n",
       " 0.6899999976158142,\n",
       " 0.6299999952316284,\n",
       " 0.7099999785423279,\n",
       " 0.75]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[load_corrects['base'][u][mask].float().mean().item() for u in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c75e7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intensity</th>\n",
       "      <th>Flip</th>\n",
       "      <th>Base</th>\n",
       "      <th>Original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   intensity   Flip   Base  Original\n",
       "0        0.1  0.520  0.514      0.48\n",
       "1        0.2  0.482  0.514      0.48\n",
       "2        0.3  0.478  0.514      0.48"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7f50b136",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0.3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [116]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m intensity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m\n\u001b[1;32m      2\u001b[0m load_corrects \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflip\u001b[39m\u001b[38;5;124m'\u001b[39m: [(flip_interventions[intensity][u][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m flip_interventions[intensity][u][\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mflip_interventions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mintensity\u001b[49m\u001b[43m]\u001b[49m))],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m'\u001b[39m: [(flip_interventions[\u001b[38;5;241m0\u001b[39m][u][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m flip_interventions[\u001b[38;5;241m0\u001b[39m][u][\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flip_interventions[\u001b[38;5;241m0\u001b[39m]))],\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     'none': [(no_intervention[u][0] == no_intervention[u][1]) for u in range(5)],\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mstack(load_corrects[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflip\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean(), torch\u001b[38;5;241m.\u001b[39mstack(load_corrects[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m     10\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0.3"
     ]
    }
   ],
   "source": [
    "intensity = 0.3\n",
    "load_corrects = {\n",
    "    'flip': [(flip_interventions[intensity][u][0] == flip_interventions[intensity][u][1]) for u in range(len(flip_interventions[intensity]))],\n",
    "    'base': [(flip_interventions[0][u][0] == flip_interventions[0][u][1]) for u in range(len(flip_interventions[0]))],\n",
    "#     'none': [(no_intervention[u][0] == no_intervention[u][1]) for u in range(5)],\n",
    "\n",
    "}\n",
    "print(torch.stack(load_corrects['flip']).float().mean(), torch.stack(load_corrects['base']).float().mean())\n",
    "\n",
    "K = 100\n",
    "# for target_class in range(10):\n",
    "all_dfs = []\n",
    "print(cifar_label_list[target_class], base_accs[target_class], orig_accs[target_class])\n",
    "for v in range(1):\n",
    "    dfs = []\n",
    "    for target_c in range(10):\n",
    "#     for target_c in [target_class]:\n",
    "        xaxis = np.arange(20, 200, 5)\n",
    "        indices, caption = saved_caption_and_most_relevant_imgs[(target_c, 0, 'neg')]\n",
    "        base, _ = get_cdf(load_corrects['base'][v][indices].float(), xaxis)\n",
    "        flip, _ = get_cdf(load_corrects[('flip')][v][indices].float(), xaxis)\n",
    "#         none, _ = get_cdf(load_corrects[('none')][v][indices].float(), xaxis)\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df['Top K'] = xaxis\n",
    "        df['Adding generic synthetic images'] = base\n",
    "        df['Adding synthetic images via SVM'] = flip\n",
    "#         df['No intervention'] = none\n",
    "\n",
    "        df = df.melt('Top K', var_name='Order', value_name='Subpopulation Accuracy')\n",
    "        df['Class'] = target_c\n",
    "        dfs.append(df)\n",
    "    combined_df = pd.concat(dfs).reset_index()\n",
    "    combined_df = combined_df.groupby(['Top K', 'Order']).mean().reset_index()[['Top K', 'Order', 'Subpopulation Accuracy']]\n",
    "    all_dfs.append(combined_df)\n",
    "\n",
    "df = pd.concat(all_dfs).reset_index()\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "sns.lineplot(data=df, x='Top K', y='Subpopulation Accuracy', hue='Order', ax=ax)\n",
    "ax.set_xlabel(\"Top K Test Images by Caption\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48152860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000*0.25/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e29b81c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f61a4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a photo of a airplane',\n",
       " 'a photo of a automobile',\n",
       " 'a photo of a bird',\n",
       " 'a photo of a cat',\n",
       " 'a photo of a deer',\n",
       " 'a photo of a dog',\n",
       " 'a photo of a frog',\n",
       " 'a photo of a horse',\n",
       " 'a photo of a ship',\n",
       " 'a photo of a truck']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_analyzer.captions['reference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca36c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.load(\"synth_model_results.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08ec6eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_intervention = out['no_intervention']\n",
    "flip_interventions = out['flip_intervention']\n",
    "base_intervention = out['base_intervention']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "07bc68cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([3, 8, 8,  ..., 5, 1, 7]),\n",
       "  tensor([3, 8, 8,  ..., 5, 1, 7]),\n",
       "  tensor([0.9736, 0.9980, 0.9996,  ..., 0.9998, 0.9998, 0.9724])),\n",
       " (tensor([3, 8, 8,  ..., 5, 1, 7]),\n",
       "  tensor([3, 8, 8,  ..., 5, 1, 7]),\n",
       "  tensor([0.8502, 0.9268, 0.9994,  ..., 0.9996, 0.9960, 0.9489])),\n",
       " (tensor([3, 8, 8,  ..., 5, 1, 7]),\n",
       "  tensor([3, 8, 8,  ..., 5, 1, 7]),\n",
       "  tensor([0.7708, 0.9999, 1.0000,  ..., 0.9988, 0.9972, 0.9987])),\n",
       " (tensor([3, 8, 8,  ..., 5, 1, 7]),\n",
       "  tensor([3, 8, 8,  ..., 5, 1, 7]),\n",
       "  tensor([0.6072, 0.9871, 0.9984,  ..., 0.9992, 0.9999, 0.9983])),\n",
       " (tensor([3, 8, 8,  ..., 5, 1, 7]),\n",
       "  tensor([3, 8, 8,  ..., 5, 1, 7]),\n",
       "  tensor([0.8949, 0.9939, 0.9277,  ..., 0.9601, 0.8612, 0.9952]))]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260cf4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.load(\"/mnt/nfs/projects/data-transfer/mturk_target_groupings/infl_values.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc44ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_label_list = np.array([CLASS_DICT['ImageNet'][u].split(',')[0] for u in range(1000)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
